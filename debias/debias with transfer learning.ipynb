{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import secrets\n",
    "\n",
    "openai.api_key = \"our api_key\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:28<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load historical and new data\n",
    "df_1 = pd.read_csv(\"gss_with_llm_responses_1.csv\")\n",
    "df_2 = pd.read_csv(\"gss_with_llm_responses_2.csv\")\n",
    "df_3 = pd.read_csv(\"gss_with_llm_responses_3.csv\")\n",
    "df = pd.concat([df_1, df_2, df_3], ignore_index=True)\n",
    "df.rename(columns={\n",
    "    'Average_Human': 'Average_Human_Response',\n",
    "    'Average_LLM_response': 'Average_LLM_Response'\n",
    "}, inplace=True)\n",
    "\n",
    "# Delet missing data\n",
    "df = df[df['Average_Human_Response'].notna()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add embedding\n",
    "tqdm.pandas()\n",
    "df[\"Embedding\"] = df[\"Question\"].progress_apply(get_embedding)\n",
    "\n",
    "# Save to new CSVs with embeddings\n",
    "df.to_pickle(\"survey_with_embeddings.pkl\")  # Use pickle to keep list structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_beta(df, lambda_ridge=1.0):\n",
    "    \"\"\"\n",
    "    Fit ridge and compute train MSE of the debiased responses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain columns\n",
    "          - 'Embedding'  : array‐like of length d\n",
    "          - 'Average_LLM_Response'\n",
    "          - 'Average_Human_Response'\n",
    "    \"\"\"\n",
    "    \n",
    "    # stack embeddings into X (n × d)\n",
    "    X = np.vstack(df[\"Embedding\"].values)             # shape (n, d)\n",
    "    # the \"bias\" target y = LLM − Human\n",
    "    y_bias = (df[\"Average_LLM_Response\"] \n",
    "              - df[\"Average_Human_Response\"]).to_numpy()  # shape (n,)\n",
    "\n",
    "    # fit ridge WITHOUT intercept\n",
    "    model = Ridge(alpha=lambda_ridge, fit_intercept=False)\n",
    "    model.fit(X, y_bias)\n",
    "    beta_hat = model.coef_                             # shape (d,)\n",
    "\n",
    "    # compute debiased response on train\n",
    "    df[\"Debiased_Response\"] = df[\"Average_LLM_Response\"].to_numpy() - X.dot(beta_hat)\n",
    "\n",
    "    # compute train‐set MSE against the true human response\n",
    "    mse_train = np.mean((df[\"Debiased_Response\"] - df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "\n",
    "    return beta_hat, mse_train\n",
    "\n",
    "\n",
    "def fit_beta_pca(df, n_components: int = 50):\n",
    "    \"\"\"\n",
    "    1) PCA-reduce the 'Embedding' to n_components,\n",
    "    2) regress (LLM − Human) on those PCs via OLS (no intercept),\n",
    "    3) compute Debiased_Response = LLM − X_pca @ beta,\n",
    "    4) return beta, train MSE, and the fitted PCA model.\n",
    "\n",
    "    Side-effect: adds df['Debiased_Response'].\n",
    "    \"\"\"\n",
    "    # stack into matrix\n",
    "    X_orig = np.vstack(df[\"Embedding\"].values)               # (n, d_orig)\n",
    "    y_bias = (df[\"Average_LLM_Response\"] \n",
    "              - df[\"Average_Human_Response\"]).to_numpy()    # (n,)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components, random_state=0)\n",
    "    X_pca = pca.fit_transform(X_orig)                        # (n, n_components)\n",
    "\n",
    "    # OLS (no intercept)\n",
    "    ols = LinearRegression(fit_intercept=False)\n",
    "    ols.fit(X_pca, y_bias)\n",
    "    beta_hat = ols.coef_                                     # (n_components,)\n",
    "\n",
    "    # debiased response + MSE\n",
    "    df[\"Debiased_Response\"] = df[\"Average_LLM_Response\"].to_numpy() - X_pca.dot(beta_hat)\n",
    "    mse_train = np.mean((df[\"Debiased_Response\"] - df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "\n",
    "    return beta_hat, mse_train, pca\n",
    "\n",
    "\n",
    "def fit_beta_factor(df, n_components: int = 50):\n",
    "    \"\"\"\n",
    "    Same as fit_beta_pca but uses FactorAnalysis instead of PCA;\n",
    "    returns beta, train MSE, and the fitted FA model.\n",
    "    \"\"\"\n",
    "    # stack into matrix\n",
    "    X_orig = np.vstack(df[\"Embedding\"].values)\n",
    "    y_bias = (df[\"Average_LLM_Response\"] \n",
    "              - df[\"Average_Human_Response\"]).to_numpy()\n",
    "\n",
    "    # Factor Analysis\n",
    "    fa = FactorAnalysis(n_components=n_components, random_state=0)\n",
    "    X_fa = fa.fit_transform(X_orig)                          # (n, n_components)\n",
    "\n",
    "    # OLS (no intercept)\n",
    "    ols = LinearRegression(fit_intercept=False)\n",
    "    ols.fit(X_fa, y_bias)\n",
    "    beta_hat = ols.coef_\n",
    "\n",
    "    # debiased response + MSE\n",
    "    df[\"Debiased_Response\"] = df[\"Average_LLM_Response\"].to_numpy() - X_fa.dot(beta_hat)\n",
    "    mse_train = np.mean((df[\"Debiased_Response\"] - df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "\n",
    "    return beta_hat, mse_train, fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_beta_pca_penalty(\n",
    "    df,\n",
    "    n_components: int = 50,\n",
    "    penalty_coef: float = 1.0,\n",
    "    lr: float = 1e-2,\n",
    "    epochs: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    PCA → penalized-OLS via GD:\n",
    "      loss = MSE(debiased,human) + penalty_coef * mean(|y - pred| * I(y*pred<0))\n",
    "    Returns:\n",
    "      beta_hat (n_components,), mse_train, and fitted PCA.\n",
    "    Side‐effect: df['Debiased_Response'] is added.\n",
    "    \"\"\"\n",
    "    # 1) assemble data\n",
    "    X_orig = np.vstack(df[\"Embedding\"].values)                # (n, D)\n",
    "    llm   = df[\"Average_LLM_Response\"].to_numpy()             # (n,)\n",
    "    human = df[\"Average_Human_Response\"].to_numpy()           # (n,)\n",
    "    y = llm - human                                           # true bias\n",
    "\n",
    "    # 2) reduce\n",
    "    pca = PCA(n_components=n_components, random_state=0)\n",
    "    X = pca.fit_transform(X_orig)                             # (n, k)\n",
    "\n",
    "    # 3) torch tensors\n",
    "    X_t     =   torch.from_numpy(X).float()                   # (n,k)\n",
    "    y_t     =   torch.from_numpy(y).float()                   # (n,)\n",
    "    llm_t   =   torch.from_numpy(llm).float()                 # (n,)\n",
    "    human_t =   torch.from_numpy(human).float()               # (n,)\n",
    "\n",
    "    # 4) params + optimizer\n",
    "    beta = torch.zeros(n_components, requires_grad=True)\n",
    "    opt  = torch.optim.Adam([beta], lr=lr)\n",
    "\n",
    "    # 5) GD loop\n",
    "    for _ in range(epochs):\n",
    "        pred = X_t @ beta                                     # (n,)\n",
    "        debiased = llm_t - pred                               # (n,)\n",
    "\n",
    "        # MSE loss\n",
    "        mse_loss = torch.mean((debiased - human_t)**2)\n",
    "\n",
    "        # sign‐mismatch penalty\n",
    "        mask = (y_t * pred < 0).float()                       # 1 if wrong sign\n",
    "        pen  = torch.mean(mask * torch.abs(y_t - pred))\n",
    "\n",
    "        loss = mse_loss + penalty_coef * pen\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # 6) finalize\n",
    "    beta_hat = beta.detach().numpy()                          # (k,)\n",
    "    df[\"Debiased_Response\"] = llm - X.dot(beta_hat)\n",
    "    mse_train = np.mean((df[\"Debiased_Response\"] - human)**2)\n",
    "\n",
    "    return beta_hat, mse_train, pca\n",
    "\n",
    "\n",
    "def fit_beta_factor_penalty(\n",
    "    df,\n",
    "    n_components: int = 50,\n",
    "    penalty_coef: float = 1.0,\n",
    "    lr: float = 1e-2,\n",
    "    epochs: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Same as fit_beta_pca but uses FactorAnalysis instead of PCA.\n",
    "    Returns beta_hat, mse_train, and fitted FA.\n",
    "    \"\"\"\n",
    "    X_orig = np.vstack(df[\"Embedding\"].values)\n",
    "    llm   = df[\"Average_LLM_Response\"].to_numpy()\n",
    "    human = df[\"Average_Human_Response\"].to_numpy()\n",
    "    y     = llm - human\n",
    "\n",
    "    fa = FactorAnalysis(n_components=n_components, random_state=0)\n",
    "    X = fa.fit_transform(X_orig)                              # (n, k)\n",
    "\n",
    "    X_t     = torch.from_numpy(X).float()\n",
    "    y_t     = torch.from_numpy(y).float()\n",
    "    llm_t   = torch.from_numpy(llm).float()\n",
    "    human_t = torch.from_numpy(human).float()\n",
    "\n",
    "    beta = torch.zeros(n_components, requires_grad=True)\n",
    "    opt  = torch.optim.Adam([beta], lr=lr)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        pred = X_t @ beta\n",
    "        debiased = llm_t - pred\n",
    "\n",
    "        mse_loss = torch.mean((debiased - human_t)**2)\n",
    "        mask     = (y_t * pred < 0).float()\n",
    "        pen      = torch.mean(mask * torch.abs(y_t - pred))\n",
    "        loss     = mse_loss + penalty_coef * pen\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    beta_hat = beta.detach().numpy()\n",
    "    df[\"Debiased_Response\"] = llm - X.dot(beta_hat)\n",
    "    mse_train = np.mean((df[\"Debiased_Response\"] - human)**2)\n",
    "\n",
    "    return beta_hat, mse_train, fa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(12, 5)\n",
      "Embedding shape: 1536\n",
      "λ= 0.01 → train MSE = 0.0049\n",
      "λ=  0.1 → train MSE = 0.0861\n",
      "λ=  1.0 → train MSE = 0.4322\n",
      "λ=  5.0 → train MSE = 0.7099\n",
      "λ= 10.0 → train MSE = 0.7904\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file (with embeddings as lists)\n",
    "df = pd.read_pickle(\"survey_with_embeddings.pkl\")\n",
    "\n",
    "# this will randomly select 100 rows for train, and the other 12 for valid\n",
    "train_df, valid_df = train_test_split(\n",
    "    df,\n",
    "    train_size=100,\n",
    "    random_state=8566,   # for reproducibility\n",
    "    shuffle=True\n",
    ")\n",
    "print(train_df.shape)  # (100, )\n",
    "print(valid_df.shape)  # (12, )\n",
    "print(\"Embedding shape:\", len(df[\"Embedding\"].iloc[0]))\n",
    "\n",
    "# your list of regularization strengths\n",
    "lambdas = [0.01, 0.1, 1.0, 5.0, 10.0]\n",
    "\n",
    "# a place to collect (lambda, mse, beta) tuples\n",
    "results = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    # fit on a fresh copy so we don't overwrite Debiased_Response repeatedly\n",
    "    beta_hat, mse_train = fit_beta(train_df.copy(), lambda_ridge=lam)\n",
    "    \n",
    "    # print out for quick console feedback\n",
    "    print(f\"λ={lam:>5} → train MSE = {mse_train:.4f}\")\n",
    "    \n",
    "    # record into our list\n",
    "    results.append({\n",
    "        \"lambda\":        lam,\n",
    "        \"mse_train\":     mse_train,\n",
    "        \"beta_hat\":      beta_hat  # this is a length-d numpy array\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.22868321909503128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_Name</th>\n",
       "      <th>Average_Human_Response</th>\n",
       "      <th>Question</th>\n",
       "      <th>Average_LLM_Response</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Debiased_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abfirm</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>How firm are you about your opinion on abortio...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[0.0027009211480617523, -0.004779394716024399,...</td>\n",
       "      <td>4.026930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natchld</td>\n",
       "      <td>1.496186</td>\n",
       "      <td>We are faced with many problems in this countr...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.032813724130392075, -0.015181060880422592, ...</td>\n",
       "      <td>1.457039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawimp</td>\n",
       "      <td>1.716904</td>\n",
       "      <td>How important is the law enforcement issue to ...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.005202507134526968, -0.008557395078241825, ...</td>\n",
       "      <td>2.083203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marhisp</td>\n",
       "      <td>2.643818</td>\n",
       "      <td>What about having a close relative marry a Jew...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>[-0.011182423681020737, 0.007882031612098217, ...</td>\n",
       "      <td>2.823690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conbus</td>\n",
       "      <td>1.934551</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.03869510814547539, -0.029890233650803566, 0...</td>\n",
       "      <td>2.070480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>life</td>\n",
       "      <td>1.587822</td>\n",
       "      <td>In general, do you find life exciting, pretty ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.012269247323274612, -0.015354420989751816,...</td>\n",
       "      <td>1.017410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>letineur</td>\n",
       "      <td>3.398006</td>\n",
       "      <td>What about the number of immigrants from Europ...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[-0.022011730819940567, 0.00751867052167654, 0...</td>\n",
       "      <td>3.284984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alienat1</td>\n",
       "      <td>1.465340</td>\n",
       "      <td>Now I want to read you some things some people...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.023283887654542923, 0.01102173700928688, -0...</td>\n",
       "      <td>1.270408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hapcohab</td>\n",
       "      <td>1.458306</td>\n",
       "      <td>Taking things all together, would you say that...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.008415235206484795, -0.058157648891210556,...</td>\n",
       "      <td>1.016566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>conclerg</td>\n",
       "      <td>1.964817</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.023766914382576942, -0.022856036201119423, ...</td>\n",
       "      <td>2.096062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_Name  Average_Human_Response  \\\n",
       "0        abfirm                3.428571   \n",
       "1       natchld                1.496186   \n",
       "2        lawimp                1.716904   \n",
       "3       marhisp                2.643818   \n",
       "4        conbus                1.934551   \n",
       "5          life                1.587822   \n",
       "6      letineur                3.398006   \n",
       "7      alienat1                1.465340   \n",
       "8      hapcohab                1.458306   \n",
       "9      conclerg                1.964817   \n",
       "\n",
       "                                            Question  Average_LLM_Response  \\\n",
       "0  How firm are you about your opinion on abortio...              4.000000   \n",
       "1  We are faced with many problems in this countr...              1.166667   \n",
       "2  How important is the law enforcement issue to ...              2.000000   \n",
       "3  What about having a close relative marry a Jew...              2.666667   \n",
       "4  I am going to name some institutions in this c...              2.000000   \n",
       "5  In general, do you find life exciting, pretty ...              1.000000   \n",
       "6  What about the number of immigrants from Europ...              3.000000   \n",
       "7  Now I want to read you some things some people...              1.166667   \n",
       "8  Taking things all together, would you say that...              1.000000   \n",
       "9  I am going to name some institutions in this c...              2.000000   \n",
       "\n",
       "                                           Embedding  Debiased_Response  \n",
       "0  [0.0027009211480617523, -0.004779394716024399,...           4.026930  \n",
       "1  [0.032813724130392075, -0.015181060880422592, ...           1.457039  \n",
       "2  [0.005202507134526968, -0.008557395078241825, ...           2.083203  \n",
       "3  [-0.011182423681020737, 0.007882031612098217, ...           2.823690  \n",
       "4  [0.03869510814547539, -0.029890233650803566, 0...           2.070480  \n",
       "5  [-0.012269247323274612, -0.015354420989751816,...           1.017410  \n",
       "6  [-0.022011730819940567, 0.00751867052167654, 0...           3.284984  \n",
       "7  [0.023283887654542923, 0.01102173700928688, -0...           1.270408  \n",
       "8  [-0.008415235206484795, -0.058157648891210556,...           1.016566  \n",
       "9  [0.023766914382576942, -0.022856036201119423, ...           2.096062  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embeddings matrix on valid\n",
    "X_val = np.vstack(valid_df[\"Embedding\"].values)\n",
    "# raw llm\n",
    "y_llm = valid_df[\"Average_LLM_Response\"].to_numpy()\n",
    "# corrected\n",
    "valid_df[\"Debiased_Response\"] = y_llm - X_val.dot(results[3]['beta_hat'])\n",
    "\n",
    "# evaluate on valid\n",
    "mse_valid = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "print(\"Validation MSE:\", mse_valid)\n",
    "# list the row‐indices you want to keep\n",
    "keep_idx = [35, 2, 8, 43, 22, 18, 70, 12, 17, 82]\n",
    "\n",
    "# select them directly from valid_df\n",
    "selected_df = valid_df.loc[keep_idx].reset_index(drop=True)\n",
    "selected_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGHCAYAAADyXCsbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpCklEQVR4nO3dd1gUV9sG8HtZelVAqgrYxa5oxN7AWGPU6GfvUVETo9FojCJ2TWJMjD32Xl41mhCV2LsRe48RJSqIFVD67vn+IKyuu8DuMku9f9fF+2Zmzsw8e1x2H04bmRBCgIiIiEhCJnkdABERERU+TDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMCjfunLlCgYMGAAfHx9YWlrC1tYWtWvXxrx58/DixYu8Di9LU6dOhUwmM+jc0NBQTJ06Vesxb29v9O/f3/DADNSsWTPIZDKtP97e3ka/d7NmzXL93Jxas2YNZDIZ7t+/n2mZWrVqwdPTEwqFItMyDRs2hLOzM1JSUnIc05EjRyCTyXDkyJEcX4soO6Z5HQCRNitWrEBQUBAqVqyIcePGwdfXF6mpqTh//jyWLl2K06dPY9euXXkdplGEhoZi0aJFWpOMXbt2wd7ePveDAlCmTBls3LhRY7+FhUUeRKObxYsX53UIWRo0aBBGjRqF/fv3o23bthrH79y5g1OnTmH06NEwNzfP8f1q166N06dPw9fXN8fXIsoOEwzKd06fPo3hw4cjICAAu3fvVvsCCwgIwNixY7Fv3748jDDv1KpVK8/ubWVlhfr16+fZ/Q2R379Ie/XqhXHjxmHVqlVaE4xVq1YBAAYOHJij+6SmpkImk8He3r7A/RtSwcUuEsp3Zs2aBZlMhuXLl2v969jc3BwdO3ZUbctkMq1/7b/fnZDRZH3o0CEMGTIETk5OsLe3R9++ffHmzRtER0ejW7duKFasGNzd3fHll18iNTVVdX5mzcv379+HTCbDmjVrsnxdW7duRWBgINzd3WFlZYXKlStjwoQJePPmjapM//79sWjRItXryvjJaGZ/9zU9ffoU5ubmmDx5ssa9bt26BZlMhp9++km1Lzo6GkOHDkXJkiVhbm4OHx8fhISEIC0tLcu4dSWEQNu2beHk5ITIyEjV/oSEBFSpUgWVK1dWvdaMLqSLFy+ic+fOsLe3h4ODA3r37o2nT59me6+QkBB88MEHcHR0hL29PWrXro2VK1fi/Wc3vt9FkvFv9d1332H+/Pnw8fGBra0t/P39cebMGY37nD9/Hh07doSjoyMsLS1Rq1YtbNu2TaPcmTNn0LBhQ1haWsLDwwMTJ05Ue+9kpnjx4vj444+xd+9ePH/+XO2YQqHA+vXrUbduXVSrVg13797FgAEDUL58eVhbW8PT0xMdOnTA1atX1c7LeJ+uX78eY8eOhaenJywsLHD37l2t7+Hz58/j//7v/+Dt7Q0rKyt4e3ujR48eePDggdp1M35/Dh8+jOHDh8PZ2RlOTk7o3LkzHj9+rPHaNm3aBH9/f9ja2sLW1hY1a9bEypUr1cr8+eefaNmyJezt7WFtbY2GDRvi4MGD2dYbFQxMMChfUSgUOHToEOrUqYNSpUoZ5R6DBw+Gg4MDtmzZgm+++QabNm3CkCFD0K5dO9SoUQM7duxAv3798P3332PhwoWS3ffvv/9G27ZtsXLlSuzbtw+jR4/Gtm3b0KFDB1WZyZMno2vXrgDSW3Iyftzd3TWuV6JECbRv3x5r166FUqlUO7Z69WqYm5ujV69eANKTi3r16mH//v2YMmUK/vjjDwwaNAizZ8/GkCFDdH4NaWlpGj8Z9874UrO2tka3bt1UX7BBQUGIiIjAtm3bYGNjo3a9jz/+GOXKlcOOHTswdepU7N69G61bt872y/n+/fsYOnQotm3bhp07d6Jz584YNWoUpk+frtPrWLRoEcLCwrBgwQJs3LgRb968Qdu2bREbG6sqc/jwYTRs2BCvXr3C0qVL8euvv6JmzZro3r27WjJ548YNtGzZEq9evcKaNWuwdOlSXLx4ETNmzNAplkGDBiElJQUbNmxQ279//348fvwYgwYNAgA8fvwYTk5OmDNnDvbt24dFixbB1NQUH3zwAW7fvq1x3YkTJyIyMhJLly7F3r174eLiovX+9+/fR8WKFbFgwQLs378fc+fORVRUFOrWrYtnz55plB88eDDMzMywadMmzJs3D0eOHEHv3r3VykyZMgW9evWCh4cH1qxZg127dqFfv35qScuGDRsQGBgIe3t7rF27Ftu2bYOjoyNat27NJKOwEET5SHR0tAAg/u///k/ncwCI4OBgjf1eXl6iX79+qu3Vq1cLAGLUqFFq5Tp16iQAiPnz56vtr1mzpqhdu7Zq+/DhwwKAOHz4sFq5iIgIAUCsXr1atS84OFhk9eulVCpFamqqOHr0qAAgLl++rDo2YsSITM99/zXt2bNHABAHDhxQ7UtLSxMeHh6iS5cuqn1Dhw4Vtra24sGDB2rX++677wQAcf369UxjFUKIpk2bCgBafwYNGqRW9sSJE8LU1FSMHj1arFq1SgAQv/zyi1qZjPr54osv1PZv3LhRABAbNmxQu3fTpk0zjU2hUIjU1FQxbdo04eTkJJRKZabnZvxbVatWTaSlpan2nzt3TgAQmzdvVu2rVKmSqFWrlkhNTVW7X/v27YW7u7tQKBRCCCG6d+8urKysRHR0tKpMWlqaqFSpkgAgIiIiMo1diPT3go+Pj6hevbra/i5dughra2sRGxur9by0tDSRkpIiypcvr1aPGe/TJk2aaJyT2Xv4/eu+fv1a2NjYiB9//FG1P+P3JygoSK38vHnzBAARFRUlhBDi3r17Qi6Xi169emV6jzdv3ghHR0fRoUMHtf0KhULUqFFD1KtXL9NzqeBgCwYVOe3bt1fbrly5MgCgXbt2GvvfbybOiXv37qFnz55wc3ODXC6HmZkZmjZtCgC4efOmQdds06YN3NzcsHr1atW+jL983+23/+2339C8eXN4eHiotT60adMGAHD06NFs71W2bFn89ddfGj/vd9E0bNgQM2fOxIIFCzB8+HD07t1b9Vf4+zJaWDJ069YNpqamOHz4cJaxHDp0CK1atYKDg4OqLqdMmYLnz58jJiYm29fSrl07yOVy1Xb16tUBQPXvfffuXdy6dUsV37t11rZtW0RFRalaDQ4fPoyWLVvC1dVVdT25XI7u3btnGweQ3vIzYMAAXLlyBeHh4QCA58+fY+/evejSpYtqUG9aWhpmzZoFX19fmJubw9TUFObm5vj777+1vn+6dOmi0/1fv36Nr776CuXKlYOpqSlMTU1ha2uLN2/eaL3uu92TgGbdhYWFQaFQYMSIEZne89SpU3jx4gX69eun0Rr24Ycf4q+//lLrOqSCiYM8KV9xdnaGtbU1IiIijHYPR0dHte2M0fna9iclJUlyz9evX6Nx48awtLTEjBkzUKFCBVhbW+Pff/9F586dkZiYaNB1TU1N0adPHyxcuBCvXr1CsWLFsGbNGri7u6N169aqck+ePMHevXthZmam9TramsLfZ2lpCT8/P53i6tWrFyZPnozk5GSMGzcu03Jubm4ar8fJyUljPMK7zp07h8DAQDRr1gwrVqxQjSnZvXs3Zs6cqVNdOjk5qW1njPXJOPfJkycAgC+//BJffvml1mtk1Nnz5881Xoe215aVAQMGYOrUqVi9ejXq1KmDjRs3IiUlRS0xGzNmDBYtWoSvvvoKTZs2RfHixWFiYoLBgwdrfc3autW06dmzJw4ePIjJkyejbt26sLe3h0wmQ9u2bbVeN7u6yxhDU7JkyUzvmVG/Gd2B2rx48UKjS40KFiYYlK/I5XK0bNkSf/zxBx4+fJjlh1QGCwsLJCcna+zP6kvKEJaWlgCgcS9dvpwPHTqEx48f48iRI6pWCwB49epVjuMaMGAAvv32W2zZsgXdu3fHnj17MHr0aLW/0J2dnVG9enXMnDlT6zU8PDxyHEcGhUKBXr16oXjx4rCwsMCgQYNw8uRJrdMso6Oj4enpqdpOS0vD8+fPNb7E3rVlyxaYmZnht99+U/2bAMDu3bslew3Ozs4A0scxdO7cWWuZihUrAkj/wo2OjtY4rm1fZkqWLInAwEBs2rQJ33//PVavXo1y5cqhSZMmqjIbNmxA3759MWvWLLVznz17hmLFimlcU5d1WGJjY/Hbb78hODgYEyZMUO1PTk42eK2ZEiVKAAAePnyY6TiqjPpduHBhprNa3m0RooKJCQblOxMnTkRoaCiGDBmCX3/9VeOLKTU1Ffv27VMNjvT29saVK1fUyhw6dAivX7+WNK6MBaWuXLmi1jqwZ8+ebM/N+LB/f1bMsmXLNMq++xehlZVVtteuXLkyPvjgA6xevRoKhQLJyckYMGCAWpn27dsjNDQUZcuWRfHixbO9Zk4EBwfj+PHjOHDgAGxsbNCkSROMGzcOP/74o0bZjRs3ok6dOqrtbdu2IS0tLcvFsWQyGUxNTdUSqMTERKxfv16y11CxYkWUL18ely9f1vhCf1/z5s2xZ88ePHnyRPWlqFAosHXrVr3uOWjQIOzbtw9TpkzBpUuXMHPmTLUkQSaTabx/fv/9dzx69AjlypXT617vXlMIoXHdX375JcvFv7ISGBgIuVyOJUuWwN/fX2uZhg0bolixYrhx4wZGjhxp0H0o/2OCQfmOv78/lixZgqCgINSpUwfDhw9HlSpVkJqaiosXL2L58uWoWrWqKsHo06cPJk+ejClTpqBp06a4ceMGfv75Zzg4OEgal5ubG1q1aoXZs2ejePHi8PLywsGDB7Fz585sz23QoAGKFy+OYcOGITg4GGZmZti4cSMuX76sUbZatWoAgLlz56JNmzaQy+WoXr16lgstDRw4EEOHDsXjx4/RoEED1V/XGaZNm4awsDA0aNAAn332GSpWrIikpCTcv38foaGhWLp0abatRYmJiVqncgJQ/RUaFhaG2bNnY/LkyWjZsiUAYPbs2fjyyy/RrFkzfPzxx2rn7dy5E6ampggICMD169cxefJk1KhRA926dcs0jnbt2mH+/Pno2bMnPv30Uzx//hzfffed5At+LVu2DG3atEHr1q3Rv39/eHp64sWLF7h58yYuXLiA7du3AwC++eYb7NmzBy1atMCUKVNgbW2NRYsW6T2GoGPHjnB2dsa3334LuVyOfv36qR1v37491qxZg0qVKqF69eoIDw/Ht99+q1MrX2bs7e3RpEkTfPvtt3B2doa3tzeOHj2KlStXam0V0YW3tze+/vprTJ8+HYmJiejRowccHBxw48YNPHv2DCEhIbC1tcXChQvRr18/vHjxAl27doWLiwuePn2Ky5cv4+nTp1iyZInBr4vyibweZUqUmUuXLol+/fqJ0qVLC3Nzc2FjYyNq1aolpkyZImJiYlTlkpOTxfjx40WpUqWElZWVaNq0qbh06VKms0j++usvtftkzGh4+vSp2v5+/foJGxsbtX1RUVGia9euwtHRUTg4OIjevXuL8+fP6zSL5NSpU8Lf319YW1uLEiVKiMGDB4sLFy5onJucnCwGDx4sSpQoIWQymdpMhPdfU4bY2FhhZWUlAIgVK1Zorc+nT5+Kzz77TPj4+AgzMzPh6Ogo6tSpIyZNmiRev36t9ZwMWc0iASBSU1PF48ePhYuLi2jRooVqhoUQ6bMkOnToIIoVK6Z6HRn1Ex4eLjp06CBsbW2FnZ2d6NGjh3jy5InGvd+fRbJq1SpRsWJFYWFhIcqUKSNmz54tVq5cqTFrI7NZJN9++63Ga4SW2UiXL18W3bp1Ey4uLsLMzEy4ubmJFi1aiKVLl6qVO3nypKhfv76wsLAQbm5uYty4cWL58uU6zSJ51xdffCEAiLZt22oce/nypRg0aJBwcXER1tbWolGjRuL48eMarzFjpsj27ds1rqFtFsnDhw9Fly5dRPHixYWdnZ348MMPxbVr13T+/clsZsq6detE3bp1haWlpbC1tRW1atVSe58LIcTRo0dFu3bthKOjozAzMxOenp6iXbt2WmOngkcmxHsr0xARGdnUqVMREhKCp0+fqvrjiahw4TRVIiIikhwTDCIiIpIcu0iIiIhIcmzBICIiIskxwSAiIiLJMcEgIiIiyRW5hbaUSiUeP34MOzs7nZbSJSIionRCCMTHx8PDwwMmJlm3URS5BOPx48eZro9PRERE2fv333+zXUW2yCUYdnZ2ANIrJ+MxyPpKTU3FgQMHEBgYmOnTKUl/rFfpsU6lxzo1Dtar9IxRp3FxcShVqpTquzQrRS7ByOgWsbe3z1GCYW1tDXt7e/4iSIj1Kj3WqfRYp8bBepWeMetUlyEGHORJREREkmOCQURERJJjgkFERESSK3JjMHQhhEBaWhoUCoXW46mpqTA1NUVSUlKmZUh/RaFezczMIJfL8zoMIiKjY4LxnpSUFERFRSEhISHTMkIIuLm54d9//+VaGhIqCvUqk8lQsmRJ2Nra5nUoRERGxQTjHUqlEhEREZDL5fDw8IC5ubnWLzqlUonXr1/D1tY224VGSHeFvV6FEHj69CkePnyI8uXLsyWDiAo1JhjvSElJgVKpRKlSpWBtbZ1pOaVSiZSUFFhaWhbKL8K8UhTqtUSJErh//z5SU1OZYBAVAgqlwLmIF4iJT4KLnSXqeBVH+IOXmW7X83EEAL3OMfQa5yJeIPyZDE4RL+BfzgVyk9xtGc7TBOPYsWP49ttvER4ejqioKOzatQudOnXK8pyjR49izJgxuH79Ojw8PDB+/HgMGzZM0rgK65cb5b3C2vVDVBDlNDm4/ywBm89FIjouSXVNExmgFMh0u5h1+noUrxJSdT4nZ9eQY93f5+HuYIngDr74sKq7/hVloDxNMN68eYMaNWpgwIAB6NKlS7blIyIi0LZtWwwZMgQbNmzAyZMnERQUhBIlSuh0PhERFQ76Jgfvb798k4Lpv99AVGzOkoP3vVte27a2c7M7R4prRMcmYfiGC1jSu3auJRl5mmC0adMGbdq00bn80qVLUbp0aSxYsAAAULlyZZw/fx7fffcdEwwiokIiu+TBkOTg/W1tDPliLygEABmAkL03EODrlivdJQVqDMbp06cRGBiotq9169ZYuXIlUlNTtS6FmpycjOTkZNV2XFwcgPQpkamp6m+W1NRUCCGgVCqhVCozjUMIofr/rMqRfvSp1/v376Ns2bIIDw9HzZo1dbr+gAED8OrVK+zatSunoWYpJCQEv/76Ky5cuKBxTKlUQgiRa2MwMt7j77/XyXCs05xTKAXOP3iJmPhkuNhZoFapYvgr4hnCn8nw9593sONiFKLj3n5uS5EcZHd+USAARMUm4fTdGHzwX3ePvvR53xeoBCM6Ohqurq5q+1xdXZGWloZnz57B3V2z2Wf27NkICQnR2H/gwAGNgZympqZwc3PD69evkZKSkm088fHxer4C44mPj8esWbPw22+/4dmzZ6hWrRrmzJmD2rVrq8oIITB37lysXbsWr169Qp06dfDtt9+icuXKqjKTJk3Cpk2bYGNjg5CQELWWoV27dmHr1q3YsmWL0V9Ldl6/fg0gvZstI2nMzrRp0wBA5/KGSk5OhkKh0HqflJQUJCYm4tixY0hLSzNqHO8KCwvLtXsVFaxT7ZQC+CdOhrhUwN4M8LETiIh/u/0mDdh13wSvUt7+BS2DgIAMgBz4+z7e/r2dcU317fePk34OHD+L5zcNy7iyWsLhfQUqwQA0B8ll/NWb2eC5iRMnYsyYMartjCfBBQYGajzsLCkpCf/++y9sbW1haWmZaQxCCMTHx8POzi7fDNr79NNPcf36daxfvx4eHh7YuHEjPv74Y1y7dg2enp4AgHnz5mHx4sVYtWoVKlSogJkzZ6JLly64efMm7OzssHfvXvzvf//D/v378ffff2Pw4MHo2LEjnJyc8OrVK8yaNQthYWEGPyQuO/rUa8Y6EjY2NjrHY6y432dhYQG5XK71fklJSbCyskKTJk2yfI9JJTU1FWFhYQgICOADpCRS1OtUW+vDxX9fISY+GQ+eJ2Dr+Yd6tz4IjWRB323SR2DjDwxuwdDnD7QClWC4ubkhOjpabV9MTAxMTU3h5OSk9RwLCwtYWFho7DczM9P4cFAoFJDJZDAxMdGcSfLmjeo/lUol8OYNZHJ5ejm5HHj3y+KdshpMTAArq+zL2thkfo33JCYmYufOnfj111/RrFkzAG+b6ZctW4YZM2ZACIEff/wRkyZNQteuXQEA69atg6urK7Zs2YKhQ4fi9u3baNasGerVq4d69ephzJgxuH//PkqUKIEJEyYgKCgI3t7eOsW0d+9eTJ06VTXbp1+/fpg0aRJMTU0xbdo0LF26FFevXlX9u3Xs2BGvXr3C7t27IZPJIJfLsXjxYuzZswdHjhyBm5sb5s2bh08++eS/ajRR/b+JiQkUCgU+/fRTHDp0CNHR0ShdujSCgoLw+eefq2Lq37+/6h4A0KxZM1SvXh2Wlpb45ZdfYG5ujmHDhmHq1Kmqc2JjYzFu3Djs3r0bSUlJ8PPzww8//IAaNWqoysyZMwc//PADEhIS0K1bN5QoUUItxneZmJhAJpNpff8ZU27frygojHUqxdiH97FrIv+QAXBzsMzRlFV93vMFKsHw9/fH3r171fYdOHAAfn5+xv9Ff2flRRMAxd491rYt8Pvvb7ddXIDMmpGaNgWOHHm77e0NPHumWU7o/luZsaz5+38RW1lZ4cSJEwDSZ+BER0erjWGxsLBA06ZNcerUKQwdOhQ1atTA8uXL8fLlS9y7dw+JiYkoV64cTpw4gQsXLmDJkiU6xbN//3707t0bP/30Exo3box//vkHn376KQAgODgYkyZNwr59+zB48GDs2rULS5cuxbFjx3Dx4kW1L+XJkydjzpw5+PHHH7F+/Xr06NEDVatWVevSyaBUKlGyZEls27YNzs7OOHXqFD799FO4u7ujW7dumca6du1ajBkzBmfPnsXp06fRv39/NGzYEAEBARBCoF27dnB0dERoaCgcHBywbNkytGzZEnfu3IGjoyO2bduG4OBgLFq0CI0bN8b69evx008/oUyZMjrVFVFeejeh0GXKpTZMIAqGjHQiuINvrq2HkacJxuvXr3H37l3VdkREBC5dugRHR0eULl0aEydOxKNHj7Bu3ToAwLBhw/Dzzz9jzJgxGDJkCE6fPo2VK1di8+bNefUS8gU7Ozv4+/tj+vTpqFy5MlxdXbF582acPXsW5cuXBwBVy4+2MSwPHjwAkD5gtnfv3qhbty6srKywdu1a2NjYYPjw4VizZg2WLFmChQsXwtnZGcuXL0eVKlW0xjNz5kxMmDAB/fr1AwCUKVMG06dPx/jx4xEcHAy5XI4NGzagZs2amDBhAhYuXIjly5fDy8tLrfntk08+weDBgwEA06dPR1hYGBYuXIjFixdr3NPMzExtrI2Pjw9OnTqFbdu2ZZlgVK9eHcHBwQCA8uXL4+eff8bBgwcREBCAw4cP4+rVq4iJiVG1gn333XfYvXs3duzYgU8//RQLFizAwIEDVXHOmDEDf/75J5KSkjK9J1FuMKQ14n1MHvSX/9bBSOdW1NbBOH/+PJo3b67azhgr0a9fP6xZswZRUVGIjIxUHffx8UFoaCi++OILLFq0CB4eHvjpp59yZ4rqf4MKgfS/luPi4mBvb/+2i+RdMTGZX+f9ZvP79yUJb/369Rg4cCA8PT0hl8tRu3Zt9OzZU2Mmg7YxLO/umzp1qloXwdSpU9GqVSuYmZlhxowZuHr1Kn777Tf07dsX4eHhWmMJDw/HX3/9hZkzZ6r2KRQKJCUlISEhAdbW1ihTpgy+++47DB06FN27d0evXr00Zo74+/trbF+6dCnTOli6dCl++eUXPHjwAImJiUhJScl2hkn16tXVtt3d3RHz379feHg4Xr9+rdH9lpiYiH/++QcAcPPmTY2F3vz9/XH48OEs70skNSlaI4o6Q77Y3ewt0KNeaXg72+S/lTzvPcWB42cR2PiDoreSZ7NmzVSDNLVZs2aNxr6mTZtqnf5ndO+OiVAqAYUifZ+2VT/1GD+hV9kslC1bFkePHlXNqnB3d0f37t3h4+MDIH38CpDekvHubJuYmBiNVo0Mt27dwsaNG3Hx4kWsWrUKTZo0QYkSJdCtWzcMHDhQlWS9T6lUIiQkBJ07d9Y49m43zrFjxyCXy3H//n2kpaXptIJqZoM/t23bhi+++ALff/89/P39YWdnh2+//RZnz57N8nrvd63JZDJVoqNUKuHu7o4j73Zp/adYsWLZxkpkTNklFO8r7MmFvq0A7g6WmNyuMorbWOToi72ej6PGF7d/Wacst3UpI8U1PvBxxPObAh9oiTE3FKgxGJQ9Gxsb2NjY4OXLl9i/fz/mzZsHIL31x83NDWFhYahVqxaA9CmTR48exdy5czWuI4TAp59+iu+//x62trZQKBQa8/8zW6uidu3auH37NsqVK5dpnFu3bsXOnTtx5MgRdO/eHdOnT1d1VWQ4c+YM+vbtq7adEfv7jh8/jgYNGiAoKEi1L6OVwVC1a9dGdHQ0TE1NMx3cWrlyZa1xEknp/e4OXbo3ChMpkgNtyYK2L11DvthJOyYYhcT+/fshhEDFihVx9+5djBs3DhUrVsSAAQMApP9lPnr0aMyaNQvly5dH+fLlMWvWLFhbW6Nnz54a11uxYgVcXFzQsWNHAEDDhg0xdepUnDlzBn/88Qd8fX0z/St+ypQpaN++PUqVKoVPPvkEJiYmuHLlCq5evYoZM2bg4cOHGD58OObOnYtGjRphzZo1aNeuHVq3bg1fX1/VdbZv3w4/Pz80atQIGzduxLlz57By5Uqt9yxXrhzWrVuH/fv3w8fHB+vXr8dff/2lasExRKtWreDv749OnTph7ty5qFixIh4/fozQ0FB06tQJfn5++Pzzz9GvXz+1OK9fv85BnqSXrMZL6NI6UdBpjBfIptvB0OSAiUHuYoJRSMTGxmLixIl4+PAhHB0d0aVLF8ycOVOtC2D8+PFITExEUFAQXr58iQ8++AAHDhyAnZ2d2rWePHmCWbNm4dSpU6p99erVw9ixY9GuXTu4uLhg7dq1mcbSunVr/Pbbb5g2bRrmzZsHMzMzVKpUCYMHD4YQAv3790e9evUwcuRIAEBAQABGjhyJvn374siRI6pul5CQEGzZsgVBQUFwc3PDxo0b1RKQdw0bNgyXLl1C9+7dIZPJ0KNHDwQFBeGPP/4wuE5lMhlCQ0MxadIkDBw4EE+fPoWbmxuaNGmi6lbq3r07/vnnH3z11VdISkpCly5dMHz4cOzfv9/g+1LhV5TGS+ja+pDdeAEmBwWPTGQ1CKIQiouLg4ODA2JjY7UutBUREQEfH58sF0HSGORJkni3XuVyuU5P1y1odH2PSSU1NRWhoaFo27ZtoVuzIa/oW6eFvXtDqtYHvlelZ4w6zeo79H1swSAikpC+gy/zM0PGPugy6JGKBiYYREQ5UJgSCqnGPhABTDAonypiPXdUQCiUAmcjXiD8mQxOES8Ql6QsMN0durRGsPWBpMQEg4goE5m3Tsix7u/zeR1elgxtjSCSChMMLfjXMxkL31v5W0Hu7ng/oWBrBOU1JhjvyBhlm5CQAKt3n3hKJJGUlBQAgPz95eUpz+27FoWQvQWju0PX7g2ivMQE4x1yuRzFihVTPYvC2tpa69LUSqUSKSkpSEpK4jRVCRX2elUqlXj69Cmsra1haspfvfwgo8Ui7EY0Vp28n9fhqGQ39ZPJBBUE/JR7T8YzO2KyeGCZEAKJiYmwsrLK9NkYpL+iUK8mJiYoXbp0oX19+Vl+Xo+C4yWoMGKC8R6ZTAZ3d3e4uLionrnxvtTUVBw7dgxNmjThgjASKgr1am5uXihbZ/Kj/DqegrM3qKhggpEJuVyeaT+5XC5HWloaLC0tC+0XYV5gvVJO5NeEgt0bVFQxwSCiAi8/DdBkQkGUjgkGERVI+WGAJmdzEGWOCQYR5Xv5ZYCmm70FutUpiVcP72T61E8iSscEg4jynfwynkJbd4dSkYbQ0Nv4gC0VRFligkFE+Up+GE8xqKE3Wvm6ae3uUCryKCiiAoYJBhHlufwwngJIH1MR3MEXH1Z1z7MYiAoLJhhElKvyy3gKDtAkMq6im2C8eQNoW+dCLgcsLdXLvS81FfKkJCAxEXh3vQZtZTOYmADvPt8kIQHI7MFXMhlgbW1Y2cREQKnMPA4bG8PKJiUBiizahvUpa22dHjcAJCcDaWnp/51Rr2/evK3XzMpqY2WVXs8AkJICZLJQmt5lLS3fvlf0KZuaml4+MxYWQMaS4fqUTUtLr4vMmJu/rb+0NM06zaysQpH+b5cZM7P08vqWVSrT32sAwq5HY9YfNxEd+zb+NLkcqfL0GGRCCcvUzOtBYSJHiul/8QoBq9TM6+H9st5WAp/UKQUvZxuUsLWAn/c7yYSnTfa/9xne/53R5/eenxGZl33399/BQfffe35GaJbN+IzQ9pkKaHxG6Px5olBk/R5+nyhiYmNjBQARm/7rqPnTtq36CdbW2ssBQtGkiXpZZ+dMywo/P/WyXl6Zl/X1VS/r65t5WS8v9bJ+fpmXdXZWL9u0aeZlra3Vy7Ztm3nZ999GXbtmXfb167dl+/XLumxMzNuyQUFZl42IeFv2yy+zLnvt2tuywcFZlz137m3ZefOyLnv48NuyP/+cddnffntbdvXqrMtu2/a27LZtWZddvVpVNHX37qzL/vzz2+sePpx12Xnz3pY9dy7rssHBqqJpV65mWXZpvc7C66vfhNdXv4mGw1ZmWXZtrXaqsrVGbcyy7G+1AsSCsNti98WH4syVB1nH27Wr+ns4i7KKNm3E7t27RUpKSnrZLD4jRNOm6tflZ0Q6fkakywefEeK337Iu+95nRCwgAIjY2FiRnaLbgkFERvPviwRcuPQI958l4Mzes9icBzG0qeYBk1YV0jf0+auLiCQhE0KIvA4iN8XFxcHBwQGxjx/D3t5es4AOXSSpqanYv38/WrdpA7N3r8HmT93KZtKkqarX1q3fLhXO5k/Nsno0aaYmJmL/nj3qdZpJWSm6SDK6QB6+TtO520OqLhI3Bwt83aYyAqqkP7AQpqbp9fZfWSQkZP7adOka/U+qUonQQ4fQtm3b9DplF0m6HH5GqP3+s4skXQ4/I7R+pgI56iKJi4mBg4cHYmNjtX+HvqPotmDY2Ki/4bMq977UVCgsLdU/DDIrm5l3f+GlLPt+TFKVfffDV8qyFhZvvwQy6tXGRvt4gXfLZsfc/O2XYV6VNTPT/jpyWtbU9O0HiQ5ls6zTd8nlur+H3ymrOQNEBsjf3kvITJBortt7Qteyeg/QlMn0+/3Mquz7Xx5SXfd9Re0z4t3f/3efNqzP7z0/I9JlfEZk95n6blld6PMZgaKcYBBRjuXWmhV8vgdRwWNQgrF+/XosXboUEREROH36NLy8vLBgwQL4+Pjgo48+kjpGIson3l9hc8Gfd2DMPtasFrwiovxN7wRjyZIlmDJlCkaPHo2ZM2dC8V8/WrFixbBgwQImGESFVG6usMkFr4gKPr0TjIULF2LFihXo1KkT5syZo9rv5+eHL7/8UtLgiChv5cYKm1zwiqhw0jvBiIiIQK1atTT2W1hY4A2nghEVGsZusWD3B1HhpneC4ePjg0uXLsHLy0tt/x9//AFfX1/JAiOi3JdbLRbs/iAq/PROMMaNG4cRI0YgKSkJQgicO3cOmzdvxuzZs/HLL78YI0YiygXGarHgDBCioknvBGPAgAFIS0vD+PHjkZCQgJ49e8LT0xM//vgj/u///s8YMRKRkRizxYJdIERFm0HTVIcMGYIhQ4bg2bNnUCqVcHFxkTouIjIyY7VYsAuEiAADB3mmpaWhfPnycHZ2Vu3/+++/YWZmBm9vbynjIyKJGGMNCxnSn3z0Ravy7AIhIjV6Jxj9+/fHwIEDUb58ebX9Z8+exS+//IIjR45IFRsRSWT/9SeY+cdt6cdXsLWCiDKhd4Jx8eJFNGzYUGN//fr1MXLkSEmCIqKcUygFzka8wM77Mhw9fVnSa3N8BRFlR+8EQyaTIT4+XmN/bGysalVPIspb6uMr5JJdl+MriEhXeicYjRs3xuzZs7F582bI/3vkrEKhwOzZs9GoUSPJAyQi3XBGCBHlJ3onGPPmzUOTJk1QsWJFNG7cGABw/PhxxMXF4dChQ5IHSETZ44wQIspv9E4wfH19ceXKFfz888+4fPkyrKys0LdvX4wcORKOjo7GiJGItGCLBRHlZwatg+Hh4YFZs2ZJHQsR6YgtFkSU3xmUYLx69Qrnzp1DTEwMlEql2rG+fftKEhgRabfvWhSGb7jANSyIKF/TO8HYu3cvevXqhTdv3sDOzg4y2dsPI5lMxgSDyAgyukOiYxMx/febOU4uAK5hQUTGpXeCMXbsWAwcOBCzZs2CtbW1MWIiondI3R3C8RVElBv0TjAePXqEzz77jMkFkREZYwAnx1cQUW7SO8Fo3bo1zp8/jzJlyhgjHqIiT+oWi6ZuSgxpWw/+5VzYYkFEuUbvBKNdu3YYN24cbty4gWrVqsHMzEzteMeOHSULjqioMFaLxaQ2FaF4EI4P2B1CRLlM7wRjyJAhAIBp06ZpHJPJZFwunEhPxhxjoVSkIfSBJJclItKLib4nKJXKTH8MSS4WL14MHx8fWFpaok6dOjh+/HiW5Tdu3IgaNWrA2toa7u7uGDBgAJ4/f673fYnyg4wpp1IkF+4OlljauzYmd6gC/7JObLEgojxl0DoYUtm6dStGjx6NxYsXo2HDhli2bBnatGmDGzduoHTp0hrlT5w4gb59++KHH35Ahw4d8OjRIwwbNgyDBw/Grl278uAVEOlPyimnjjZmmNy+CtzsuYYFEeUvBiUYb968wdGjRxEZGYmUlBS1Y5999pnO15k/fz4GDRqEwYMHAwAWLFiA/fv3Y8mSJZg9e7ZG+TNnzsDb21t1Dx8fHwwdOhTz5s0z5GUQ5TqpukMy0ohZH1fjrBAiypf0TjAuXryItm3bIiEhAW/evIGjoyOePXsGa2truLi46JxgpKSkIDw8HBMmTFDbHxgYiFOnTmk9p0GDBpg0aRJCQ0PRpk0bxMTEYMeOHWjXrl2m90lOTkZycrJqOy4uDgCQmpqK1NRUnWJ9X8Z5hp5P2hX2et1//QlGbbks0SJZFpjUphJaVnTOsr4Ke53mBdapcbBepWeMOtXnWjIhhF6fd82aNUOFChWwZMkSFCtWDJcvX4aZmRl69+6Nzz//HJ07d9bpOo8fP4anpydOnjyJBg0aqPbPmjULa9euxe3bt7Wet2PHDgwYMABJSUlIS0tDx44dsWPHDo3ZLBmmTp2KkJAQjf2bNm3iWh6UK5QC+DtWhjV/myAhDXjb/qCP9F/Tpm4C1RwFytoLsDeEiHJbQkICevbsidjYWNjb22dZVu8WjEuXLmHZsmWQy+WQy+VITk5GmTJlMG/ePPTr10/nBCPDu0uNA4AQQmNfhhs3buCzzz7DlClT0Lp1a0RFRWHcuHEYNmwYVq5cqfWciRMnYsyYMartuLg4lCpVCoGBgdlWTmZSU1MRFhaGgICATBMb0l9hrNf9159gdugtRMclZ184C+lTTiuhdRVXvc4rjHWa11inxsF6lZ4x6jSjF0AXeicYZmZmqgTA1dUVkZGRqFy5MhwcHBAZGanzdZydnSGXyxEdHa22PyYmBq6u2j9EZ8+ejYYNG2LcuHEAgOrVq8PGxgaNGzfGjBkz4O6u2RdtYWEBCwsLra8jpxUuxTVIU0GvVynXtJBqWe+CXqf5EevUOFiv0pOyTvW5jt4JRq1atXD+/HlUqFABzZs3x5QpU/Ds2TOsX78e1apV0/k65ubmqFOnDsLCwvDxxx+r9oeFheGjjz7Sek5CQgJMTdVDlsvlANJbPojymlSDOLmsNxEVdHonGLNmzUJ8fDwAYPr06ejXrx+GDx+OcuXKYfXq1Xpda8yYMejTpw/8/Pzg7++P5cuXIzIyEsOGDQOQ3r3x6NEjrFu3DgDQoUMHDBkyBEuWLFF1kYwePRr16tWDh4eHvi+FSFI5fYw6p5wSUWGid4Lh5+en+u8SJUogNDTU4Jt3794dz58/x7Rp0xAVFYWqVasiNDQUXl5eAICoqCi1bpf+/fsjPj4eP//8M8aOHYtixYqhRYsWmDt3rsExEOWUQilw5p/nmPC/qwYlF5xySkSFUZ4utAUAQUFBCAoK0npszZo1GvtGjRqFUaNGGTkqIt1I0SXixu4QIiqEdEowateujYMHD6J48eKoVatWprM8AODChQuSBUeUn+W0S6SYlRkW9aqN+mW4rDcRFT46JRgfffSRaiZGp06djBkPUb4mxTLfGanEnC7V0LCcs5ThERHlGzolGMHBwQAAhUKBZs2aoXr16ihevLhRAyPKb6SaIcIuESIqCvQagyGXy9G6dWvcvHmTCQYVKTntDgGkW9OCiKgg0HuQZ7Vq1XDv3j34+PgYIx6ifCWnM0QArmlBREWT3gnGzJkz8eWXX2L69OmoU6cObGxs1I4buvw2UX6T0y4RDuIkoqJM7wTjww8/BAB07NhRbTZJxjNEFAqFdNER5ZGcdIlwECcRkQEJxuHDh40RB1G+IEWXCAdxEhEZkGA0bdrUGHEQ5bmcdIlwmW8iInUGr+SZkJCAyMhIpKSkqO2vXr16joMiym2GdolwmW8iIu30TjCePn2KAQMG4I8//tB6nGMwqCDJaZcIu0OIiLTTO8EYPXo0Xr58iTNnzqB58+bYtWsXnjx5ghkzZuD77783RoxERpGTLhHOECEiypreCcahQ4fw66+/om7dujAxMYGXlxcCAgJgb2+P2bNno127dsaIk0hSOe0S4QwRIqKsmeh7wps3b+Di4gIAcHR0xNOnTwGkL8DFB51RQaBQCoTsvWFwl8iS3rXZJUJElA29WzAqVqyI27dvw9vbGzVr1sSyZcvg7e2NpUuXwt2dH7qUf2U8qOzk3ad6d4uwS4SISD8GjcGIiooCkP4QtNatW2Pjxo0wNzfHmjVrpI6PSBKGjrdglwgRkWF0TjA6deqEwYMHo0ePHjAxSe9ZqVWrFu7fv49bt26hdOnScHbmBzDlPzlZlZOzRIiIDKNzgpGYmIhOnTrBxcUF/fv3x4ABA1C+fHlYW1ujdu3axoyRyCA5mYLKLhEiopzReZDn/v37cf/+fQwfPhzbtm1DpUqV0KRJE6xbtw6JiYnGjJFIb/uuRaHR3EPotfIsXiWm6nye7L+fjC4RJhdERIbRaxZJyZIlMXnyZNy9exd//vknvLy8EBQUBDc3NwwdOhRnz541VpxEOsvoEjFkfQvOEiEikobBS4U3b94czZs3R3x8PDZt2oSvv/4aK1euRFpampTxEenF0CmoI5uXQ8NyznyOCBGRRAxOMADg3r17WLNmDdasWYPY2Fi0atVKqriI9KZQCqw5GaFXy4UM6a0WXwRUYGJBRCQhvROMxMREbN++HatXr8axY8dQunRpDB48GAMGDECpUqWMESNRtgyZhpqRTgR38GVyQUQkMZ0TjFOnTmH16tXYtm0bUlJS0KlTJ+zfv5+tFpTnDJ2GyimoRETGo3OC0ahRI9SoUQMzZ85Er169ULx4cWPGRaQTQ8ZccAoqEZHx6ZxgnD9/nutdUL5hyLLfXJWTiCj36JxgMLmg/MLQZb/ZJUJElHtyNIuEKLcZOt5icrvK6N/Qh10iRES5hAkGFRiGjLfImIbK5IKIKHfptZInUV4xdI0LgNNQiYjyAlswKN/jmAsiooJHpwSjVq1akMl0+wvwwoULOQqI6F2GjLngst9ERHlPpwSjU6dOqv9OSkrC4sWL4evrC39/fwDAmTNncP36dQQFBRklSCqa9B1zwWW/iYjyD50SjODgYNV/Dx48GJ999hmmT5+uUebff/+VNjoqsvQdc8HxFkRE+YveYzC2b9+O8+fPa+zv3bs3/Pz8sGrVKkkCo6Jr//UnmPnHbb3GXHC8BRFR/qJ3gmFlZYUTJ06gfPnyavtPnDgBS0tLyQKjounycxlWn76s15gLrnFBRJT/6J1gjB49GsOHD0d4eDjq168PIH0MxqpVqzBlyhTJA6SiQ6EU2HnfRO8xF0wuiIjyH70TjAkTJqBMmTL48ccfsWnTJgBA5cqVsWbNGnTr1k3yAKloUCgF1p15gFcpuiUKHHNBRJS/GbQORrdu3ZhMkGQMWeeCYy6IiPI3gxKMV69eYceOHbh37x6+/PJLODo64sKFC3B1dYWnp6fUMVIhZsg6FxxzQUSU/+mdYFy5cgWtWrWCg4MD7t+/j8GDB8PR0RG7du3CgwcPsG7dOmPESYWQoetcMLkgIsr/9H4WyZgxY9C/f3/8/fffarNG2rRpg2PHjkkaHBVu5yJecJ0LIqJCSu8WjL/++gvLli3T2O/p6Yno6GhJgqLCTaEUOBfxAn9ci9L5HI65ICIqWPROMCwtLREXF6ex//bt2yhRooQkQVHhZciATo65ICIqePTuIvnoo48wbdo0pKamAgBkMhkiIyMxYcIEdOnSRfIAqfDIGNCpT7eIO8dcEBEVSHonGN999x2ePn0KFxcXJCYmomnTpihXrhzs7Owwc+ZMY8RIhYAhAzoBjrkgIiqo9O4isbe3x4kTJ3Do0CFcuHABSqUStWvXRqtWrYwRHxUC+j64DOCYCyKigs6gdTAAoEWLFmjRooWUsVAhpO+Yi8ZuSgxtWw/+5VzYckFEVIAZlGAcPHgQBw8eRExMDJRKpdoxPk2VMhiyiFYNR4EPfByZXBARFXB6j8EICQlBYGAgDh48iGfPnuHly5dqP/pavHgxfHx8YGlpiTp16uD48eNZlk9OTsakSZPg5eUFCwsLlC1blklNPmTImAt3BwuUtdcnHSEiovxK7xaMpUuXYs2aNejTp0+Ob75161aMHj0aixcvRsOGDbFs2TK0adMGN27cQOnSpbWe061bNzx58gQrV65EuXLlEBMTg7S0tBzHQtIyZBGtSW0qQfEg3HhBERFRrtE7wUhJSUGDBg0kufn8+fMxaNAgDB48GACwYMEC7N+/H0uWLMHs2bM1yu/btw9Hjx7FvXv34OjoCADw9vaWJBaSjkIpcPLuM53LZwzobFnRGaEPjBgYERHlGr0TjMGDB2PTpk2YPHlyjm6ckpKC8PBwTJgwQW1/YGAgTp06pfWcPXv2wM/PD/PmzcP69ethY2ODjh07Yvr06bCystJ6TnJyMpKTk1XbGYuEpaamqtby0FfGeYaeX5jtv/4EM0JvITouOfvCAL5uUwF963tBbiJjvRoB61R6rFPjYL1Kzxh1qs+19E4wkpKSsHz5cvz555+oXr06zMzM1I7Pnz9fp+s8e/YMCoUCrq6uavtdXV0zXXL83r17OHHiBCwtLbFr1y48e/YMQUFBePHiRabjMGbPno2QkBCN/QcOHIC1tbVOsWYmLCwsR+cXNpefy7DqTsawnuwGaQoUMwdKvLyB/ftuqB1hvUqPdSo91qlxsF6lJ2WdJiQk6FzWoKep1qxZEwBw7do1tWMymf4j/98/RwiR6XWUSiVkMhk2btwIBwcHAOkJTdeuXbFo0SKtrRgTJ07EmDFjVNtxcXEoVaoUAgMDYW9vr3e8QHoGFxYWhoCAAI0Eq6hSKAVmf38MQPYtF7L//ndG5xpoXeVtgsl6lR7rVHqsU+NgvUrPGHWq7VEhmdE7wTh8+LC+p2jl7OwMuVyu0VoRExOj0aqRwd3dHZ6enqrkAgAqV64MIQQePnyI8uXLa5xjYWEBCwsLjf1mZmY5rnAprlFYnP/nuc7dItktosV6lR7rVHqsU+NgvUpPyjrV5zp6T1OVirm5OerUqaPRdBMWFpbpINKGDRvi8ePHeP36tWrfnTt3YGJigpIlSxo1XspaTLxuM0ZGNi+LE1+14AqdRESFnE4tGJ07d8aaNWtgb2+Pzp07Z1l2586dOt98zJgx6NOnD/z8/ODv74/ly5cjMjISw4YNA5DevfHo0SOsW7cOANCzZ09Mnz4dAwYMQEhICJ49e4Zx48Zh4MCBmQ7yJONTKAWexevWetGwXAkuokVEVATolGA4ODioxkW82z2RU927d8fz588xbdo0REVFoWrVqggNDYWXlxcAICoqCpGRkarytra2CAsLw6hRo+Dn5wcnJyd069YNM2bMkCwm0o+uS4HLkN41Us/HMXcCIyKiPKVTgrF69Wqt/y2FoKAgBAUFaT22Zs0ajX2VKlXiKON8QtelwPlkVCKiosfgh51R0abPUuB8MioRUdFjUIKxY8cObNu2DZGRkUhJSVE7duHCBUkCo/xN16XAJ7erjP4NfdhyQURUxOg9i+Snn37CgAED4OLigosXL6JevXpwcnLCvXv30KZNG2PESPmIQilw+p/n+ONalE7lne0smFwQERVBerdgLF68GMuXL0ePHj2wdu1ajB8/HmXKlMGUKVPw4sULY8RI+YSuAzrf5WJnacSIiIgov9K7BSMyMlK1ToWVlRXi4+MBAH369MHmzZuljY7yjYwBnfo8IdWds0aIiIosvRMMNzc3PH/+HADg5eWFM2fOAAAiIiIghC5D/qig0WdAJ8BZI0REZECC0aJFC+zduxcAMGjQIHzxxRcICAhA9+7d8fHHH0seIOU9XQd0ZnBzsMSS3rU5a4SIqAjTewzG8uXLoVQqAQDDhg2Do6MjTpw4gQ4dOqhW4KTCRddlwPv6e6FNVXfU83FkywURURGnd4JhYmICE5O3DR/dunVDt27dJA2K8g99lgFvU9Ud/mWdjBwREREVBDolGFeuXNH5gtWrVzc4GMpfuAw4EREZSqcEo2bNmpDJZNkO4pTJZFAoFJIERnmLy4ATEVFO6JRgREREGDsOyke4DDgREeWUTglGxtNNqWjgMuBERJRTBj2L5Pbt21i4cCFu3rwJmUyGSpUqYdSoUahYsaLU8VEe0HXWCJcBJyKizOi9DsaOHTtQtWpVhIeHo0aNGqhevTouXLiAqlWrYvv27caIkXKZrst7cxlwIiLKjN4tGOPHj8fEiRMxbdo0tf3BwcH46quv8Mknn0gWHOU+hVJAqRQoZmWGV4mpWstw1ggREWVH7xaM6Oho9O3bV2N/7969ER0dLUlQlDf2XYtCo7mH0Gvl2SyTC4CzRoiIKGt6JxjNmjXD8ePHNfafOHECjRs3liQoyn26PsyMy4ATEZEu9O4i6dixI7766iuEh4ejfv36AIAzZ85g+/btCAkJwZ49e9TKUv6ny7TUYlZmWNSrNuqXcWLLBRERZUvvBCMoKAgAsHjxYixevFjrMYCLbhUkukxLfZWYChOZjMkFERHpRO8EI+NBZ1R46DotVddyREREeo/ByEpCQoKUl6NcoM/DzDgtlYiIdGXQIM+HDx9q7D979ixq1qwpRUyUSzJmjUz//WaW5WQA3DktlYiI9KB3gmFvb4/q1atjy5YtANK7TKZOnYomTZpwUGcBouusEU5LJSIiQ+g9BmPPnj1YunQpBg8ejD179uD+/fuIjIzE77//jlatWhkjRpIYH2ZGRETGZtCzSIYNG4YHDx5g7ty5MDU1xZEjR9CgQQOpYyMj4cPMiIjI2PTuInn58iW6dOmCJUuWYNmyZejWrRsCAwM1pqxS/sWHmRERkbHp3YJRtWpV+Pj44OLFi/Dx8cGQIUOwdetWBAUF4ffff8fvv/9ujDhJQnyYGRERGZveLRjDhg3DsWPH4OPjo9rXvXt3XL58GSkpKZIGR9JSKAVO//Mc0bGJsLfMPLfkrBEiIsopvVswJk+erHV/yZIlERYWluOAyDj2XYtCyN4bnDVCRES5QucWjHnz5iExMVG1fezYMSQnv12gKT4+Xm2pcMo/dJ2SCvBhZkREJA2dE4yJEyciPj5etd2+fXs8evRItZ2QkIBly5ZJGx3lmC5TUh1tzPBD95rYPKQ+TnzVgskFERHlmM5dJEKILLcpf9JlSuqLN6lws7eEf1mnXIqKiIgKO0mfRUL5Dx9kRkREeYEJRiHHKalERJQX9JpF8ssvv8DW1hYAkJaWhjVr1sDZ2RkA1MZnUP6gUAoolQLFrMzwKjFVaxkZ0gd2ckoqERFJSecEo3Tp0lixYoVq283NDevXr9coQ/mDLtNSOSWViIiMRecE4/79+0YMg6SUMS01u2G4fJAZEREZi0EPO6P8S5dpqcWszLCoV23UL+PElgsiIjIKDvIsZHSZlvoqMRUmMhmTCyIiMhomGIUMp6USEVF+wASjkOG0VCIiyg+YYBQy9Xwc4e6QefLAJ6USEVFuMCjB+Oeff/DNN9+gR48eiImJAQDs27cP169flzQ40o9CKXAu4gUCfV21Hue0VCIiyi16JxhHjx5FtWrVcPbsWezcuROvX78GAFy5cgXBwcGSB0i62XctCo3mHkKPFWew9vQDrWX4pFQiIsotek9TnTBhAmbMmIExY8bAzs5Otb958+b48ccfJQ2OdJPduheDGnqjla8b6vk4suWCiIhyhd4tGFevXsXHH3+ssb9EiRJ4/vy5JEGR7rJb90IGIPRaNJMLIiLKVXonGMWKFUNUVJTG/osXL8LT01OSoEh32a17IQBExSbhXMSL3AuKiIiKPL0TjJ49e+Krr75CdHQ0ZDIZlEolTp48iS+//BJ9+/Y1RoyUBa57QURE+ZHeCcbMmTNRunRpeHp64vXr1/D19UWTJk3QoEEDfPPNN8aIkbLAdS+IiCg/0jvBMDMzw8aNG3Hnzh1s27YNGzZswK1bt7B+/XrI5XK9A1i8eDF8fHxgaWmJOnXq4Pjx4zqdd/LkSZiamqJmzZp637Mw4boXRESUHxk0TRUAypYti65du6Jbt24oX768QTffunUrRo8ejUmTJuHixYto3Lgx2rRpg8jIyCzPi42NRd++fdGyZUuD7luYyE1k+LptJa3HuO4FERHlFb0TjICAAJQuXRoTJkzAtWvXcnTz+fPnY9CgQRg8eDAqV66MBQsWoFSpUliyZEmW5w0dOhQ9e/aEv79/ju5fkCmUAqf/eY5fLz3ClYexAID3cwiue0FERHlF73UwHj9+jC1btmDz5s2YN28eqlatit69e6Nnz54oWbKkztdJSUlBeHg4JkyYoLY/MDAQp06dyvS81atX459//sGGDRswY8aMbO+TnJyM5ORk1XZcXBwAIDU1FampqTrH+66M8ww9P6f2X3+CGaG3EB2XrLb/oxru6FLbEzHxyXCxs4CfV3HITWR5Fqe+8rpeCyPWqfRYp8bBepWeMepUn2vJhBCZLaGQrYiICGzatAmbN2/GrVu30KRJExw6dEincx8/fgxPT0+cPHkSDRo0UO2fNWsW1q5di9u3b2uc8/fff6NRo0Y4fvw4KlSogKlTp2L37t24dOlSpveZOnUqQkJCNPZv2rQJ1tbWOsWan1x+LsOqOxkNT+82WaT/Mw6soEQNJ4P/SYmIiDKVkJCAnj17IjY2Fvb29lmW1bsF410+Pj6YMGECatSogcmTJ6vGZ+hDJlNv1xdCaOwDAIVCgZ49eyIkJAQVKlTQ+foTJ07EmDFjVNtxcXEoVaoUAgMDs62czKSmpiIsLAwBAQEwMzMz6BqGUCgFZn9/DECylqMyyAD88cQa43s1KZBjLvKqXgsz1qn0WKfGwXqVnjHqNKMXQBcGJxgnT57Exo0bsWPHDiQlJaFjx46YNWuWzuc7OztDLpcjOjpabX9MTAxcXTUf1hUfH4/z58/j4sWLGDlyJABAqVRCCAFTU1McOHAALVq00DjPwsICFhYWGvvNzMxyXOFSXEMf5/95rtEt8q70RbWScfFhPPzLOuVaXFLL7XotClin0mOdGgfrVXpS1qk+19E7wfj666+xefNmPH78GK1atcKCBQvQqVMnvbsbzM3NUadOHYSFhaktPR4WFoaPPvpIo7y9vT2uXr2qtm/x4sU4dOgQduzYAR8fH31fSoHDRbWIiKig0DvBOHLkCL788kt0794dzs7OObr5mDFj0KdPH/j5+cHf3x/Lly9HZGQkhg0bBiC9e+PRo0dYt24dTExMULVqVbXzXVxcYGlpqbG/sOKiWkREVFDonWBkNcNDX927d8fz588xbdo0REVFoWrVqggNDYWXlxcAICoqKts1MYqSjEW1omOTtD7cTIb0qalcVIuIiPKaTgnGnj170KZNG5iZmWHPnj1Zlu3YsaNeAQQFBSEoKEjrsTVr1mR57tSpUzF16lS97leQyU1kCO7gi2EbLmgc46JaRESUn+iUYHTq1AnR0dFwcXFBp06dMi0nk8mgUCikio20+LCqOwJ9XXHgxhO1/W4Olgju4MtFtYiIKF/QKcFQKpVa/5tyj0IpcC7iBR6+TMDJu88AAGMDKqC0kzVc7NK7RdhyQURE+YXeYzDWrVuH7t27a0z9TElJwZYtW/jIdiPYdy0KIXtvICr27ewQuYkMZUvYom11tlgQEVH+o/ezSAYMGIDY2FiN/fHx8RgwYIAkQdFb+65FYfiGC2rJBZDeojFi0wXsuxaVR5ERERFlTu8EI7OVNh8+fAgHBwdJgqJ0CqVAyN4bWmeMZAjZewMKJZcGJyKi/EXnLpJatWpBJpNBJpOhZcuWMDV9e6pCoUBERAQ+/PBDowRZVJ2LeKHRcvGu9JU7k3Au4kWBXrmTiIgKH50TjIzZI5cuXULr1q1ha2urOmZubg5vb2906dJF8gCLMq7cSUREBZXOCUZwcDAAwNvbG927d4elJVeLNDau3ElERAWV3mMw+vXrx+Qil2Ss3JnZ5FMZAHeu3ElERPmQ3gmGQqHAd999h3r16sHNzQ2Ojo5qPySdjJU7M1sWHODKnURElD/pnWCEhIRg/vz56NatG2JjYzFmzBh07twZJiYmRWrZ7tzyYVV3lC1ho7HfzcESS3rX5sqdRESUL+m90NbGjRuxYsUKtGvXDiEhIejRowfKli2L6tWr48yZM/jss8+MEWeRdedJPP55+gYmMuDnnrWRqlBy5U4iIsr39E4woqOjUa1aNQCAra2tatGt9u3bY/LkydJGV4RlLA2+5MhdAECryi5oW42tFUREVDDo3UVSsmRJREWlrx5Zrlw5HDhwAADw119/aSwfTobZdy0KjeYeQo8VZ3Ds7/Tnjvx1/xVX7SQiogJD7wTj448/xsGDBwEAn3/+OSZPnozy5cujb9++GDhwoOQBFjWZLQ3+KiEFwzdwaXAiIioY9O4imTNnjuq/u3btipIlS+LUqVMoV64cOnbsKGlwRU1WS4MLpM8cCdl7AwG+bhx/QURE+ZreCcb76tevj/r160sRS5HHpcGJiKiw0CnB2LNnj84XZCuG4bg0OBERFRY6JRgZzyHJjkwmg0KhyEk8RRqXBiciosJCpwRDqVQaOw7C26XBM+smkSF9gS0uDU5ERPmd3rNIyHgylgbXhkuDExFRQaL3IM9p06ZleXzKlCkGB0NAtZLFtO53c7BEcAdfLg1OREQFgt4Jxq5du9S2U1NTERERAVNTU5QtW5YJRg7tOP8QAFDfxxGft6qAmPgkLg1OREQFjt4JxsWLFzX2xcXFoX///vj4448lCaooUigFzt57jrWnIwAAn/iV5FRUIiIqsHK8DgYA2NvbY9q0aWjfvj369OkjxSWLlH3XohCy94ba4M5v99+GjYUpu0SIiKhAkmyQ56tXr1QPPiPdZbY0+JO4ZC4NTkREBZbeLRg//fST2rYQAlFRUVi/fj0+/PBDyQIrCrg0OBERFVZ6Jxg//PCD2raJiQlKlCiBfv36YeLEiZIFVhRwaXAiIiqs9E4wIiIijBFHkcSlwYmIqLDiQlt5iEuDExFRYaV3C0ZSUhIWLlyIw4cPIyYmRmMZ8QsXLkgWXGHHpcGJiKiw0jvBGDhwIMLCwtC1a1fUq1cPMhkHHxoqY2nwYRs0kzIuDU5ERAWZ3gnG77//jtDQUDRs2NAY8RQ5Dcs5w9REhjSl+lwSLg1OREQFmd4JhqenJ+zs7IwRS5F06FYM0pQCPs7WmPVxNcTEJ3NpcCIiKvD0HuT5/fff46uvvsKDBw+MEU+R88fVaABA22ru8C/rjI9qesK/rBOTCyIiKtD0bsHw8/NDUlISypQpA2tra5iZmakdf/HihWTBFXaJKQocuRMDAGjDrhAiIipE9E4wevTogUePHmHWrFlwdXXlIE8DKJQC5yJe4M8b0UhKVcKzmCWqeNjndVhERESS0TvBOHXqFE6fPo0aNWoYI55CT9uDzV4lpGL/9WgO6CQiokJD7zEYlSpVQmJiojFiKfQye7DZmxQFH2xGRESFit4Jxpw5czB27FgcOXIEz58/R1xcnNoPaZfVg80yhOy9AYUyqxJEREQFg95dJBlPTG3ZsqXafiEEZDIZFAqFNJEVMnywGRERFSV6JxiHDx82RhyFHh9sRkRERYneCUbTpk2NEUehxwebERFRUaJ3gnHs2LEsjzdp0sTgYAqzjAebRccmaR2HwQebERFRYaJ3gtGsWTONfe+uhcExGNplPNhsOB9sRkRERYDes0hevnyp9hMTE4N9+/ahbt26OHDggDFiLDQ+rOqO77tprh/i5mCJJb1rcx0MIiIqNPRuwXBwcNDYFxAQAAsLC3zxxRcIDw+XJLDCyspMDgBwt7fEhLaV+GAzIiIqlPROMDJTokQJ3L59W6rLFVpHbj8FAHxYzQ0f1fTM42iIiIiMQ+8E48qVK2rbQghERUVhzpw5XD48G0IIHL2TnmA0q+iSx9EQEREZj94JRs2aNSGTySCE+lyI+vXrY9WqVZIFVhjdfhKP6LgkWJqZ4APOFiEiokJM70GeERERuHfvHiIiIhAREYEHDx4gISEBp06dQqVKlfQOYPHixfDx8YGlpSXq1KmD48ePZ1p2586dCAgIQIkSJWBvbw9/f3/s379f73vmlYzuEf8yTrD8bywGERFRYaR3guHl5aX2U6pUKVhaGrY41NatWzF69GhMmjQJFy9eROPGjdGmTRtERkZqLX/s2DEEBAQgNDQU4eHhaN68OTp06ICLFy8adP/colAKnP7nOXaE/wsAaFzeOY8jIiIiMi6dE4xDhw7B19dX6wPNYmNjUaVKlSxbH7SZP38+Bg0ahMGDB6Ny5cpYsGABSpUqhSVLlmgtv2DBAowfPx5169ZF+fLlMWvWLJQvXx579+7V6765ad+1KDSaewg9VpzB3Zg3AIAlR+7xyalERFSo6TwGY8GCBRgyZAjs7e01jjk4OGDo0KGYP38+GjdurNP1UlJSEB4ejgkTJqjtDwwMxKlTp3S6hlKpRHx8PBwdMx/PkJycjOTkZNV2RoKUmpqK1NRUne7zvozzsjt///UnGLXlssbKnc9eJ2P4hgtY+H810LqKq0ExFEa61ivpjnUqPdapcbBepWeMOtXnWjonGJcvX8bcuXMzPR4YGIjvvvtO5xs/e/YMCoUCrq7qX7Curq6Ijo7W6Rrff/893rx5g27dumVaZvbs2QgJCdHYf+DAAVhbW+scrzZhYWGZHlMKIOSC/L/kQn2NC/Hf/36z8xJS7yvAJTDUZVWvZBjWqfRYp8bBepWelHWakJCgc1mdE4wnT57AzMws8wuZmuLp06c63zjDu8uMA28f+56dzZs3Y+rUqfj111/h4pL5lM+JEydizJgxqu24uDiUKlUKgYGBWltjdJGamoqwsDAEBARkWidnI17g1ZnzWVxFhlcpQAnf+pxR8h9d6pX0wzqVHuvUOFiv0jNGnWobJpEZnRMMT09PXL16FeXKldN6/MqVK3B3132pa2dnZ8jlco3WipiYGI1Wjfdt3boVgwYNwvbt29GqVassy1pYWMDCwkJjv5mZWY4rPKtrPE9I0+kazxPS+Mv0Hin+bUgd61R6rFPjYL1KT8o61ec6Og/ybNu2LaZMmYKkpCSNY4mJiQgODkb79u11vrG5uTnq1Kmj0XQTFhaGBg0aZHre5s2b0b9/f2zatAnt2rXT+X65jY9nJyKiokznFoxvvvkGO3fuRIUKFTBy5EhUrFgRMpkMN2/exKJFi6BQKDBp0iS9bj5mzBj06dMHfn5+8Pf3x/LlyxEZGYlhw4YBSO/eePToEdatWwcgPbno27cvfvzxR9SvX1/V+mFlZaX1GSl5iY9nJyKiokznBMPV1RWnTp3C8OHDMXHiRNVKnjKZDK1bt8bixYuz7dp4X/fu3fH8+XNMmzYNUVFRqFq1KkJDQ+Hl5QUAiIqKUlsTY9myZUhLS8OIESMwYsQI1f5+/fphzZo1et3b2Ph4diIiKsr0Wircy8sLoaGhePnyJe7evQshBMqXL4/ixYsbHEBQUBCCgoK0Hns/aThy5IjB98kLH1Z1x5iACvg+7I7afjcHSwR38OXj2YmIqNAy6GmqxYsXR926daWOpVBKUSgBAP5lnfB/dUvx8exERFQkSPa4dtLu+N/PAAAf1/Tk49mJiKjI0PtZJKS72IRUXHn4CgDQiM8fISKiIoQJhhGdvvcMSgGULWEDj2JWeR0OERFRrmGCYUTH/useaVy+RB5HQkRElLuYYBjRCVWCwe4RIiIqWjjI0wgUSoG9lx8h8kUCTGSAnzcX0yIioqKFLRgS23ctCo3mHsLorZcBpD9V9cMFx7DvWlQeR0ZERJR7mGBIaN+1KAzfcAFRserPa4mOTcLwDReYZBARUZHBBEMiCqVAyN4bWp87krEvZO8NKJTaShARERUuTDAkci7ihUbLxbsEgKjYJJyLeJF7QREREeURJhgSiYnPPLkwpBwREVFBxgRDIi52lpKWIyIiKsiYYEikno8j3B0skdkjzGQA3B3SH3RGRERU2DHBkIjcRIbgDr5aB3lmJB3BHXz5FFUiIioSmGBI6MOq7hjUyEdjv5uDJZb0ro0Pq7rnQVRERES5jyt5Skwp0tswAn1d0a66O1zs0rtF2HJBRERFCRMMiV148BIA0K66Oz6q6ZnH0RAREeUNdpFIKClVgeuP4wAAtUsXz+NoiIiI8g4TDAldeRiLNKVACTsLlCxuldfhEBER5RkmGBK6EJnePVK7dDHIZBxzQURERRcTDAmF/zf+oo4Xu0eIiKhoY4IhESEELqpaMJhgEBFR0cYEQyKRLxLw7HUKzOQyVPV0yOtwiIiI8hQTDIlkjL+o4uEASzN5HkdDRESUt5hgSEChFPj9ShQAwMPBEgqltgXDiYiIig4mGDm071oUGs09hD9vxgAAQq9Fo9HcQ9h3LSqPIyMiIso7TDByYP/1Jxi+4QKiYpPU9kfHJmH4hgtMMoiIqMhigmEgpQBmhN7S+vTUjH0he2+wu4SIiIokJhgG+idOhui45EyPCwBRsUk4F/Ei94IiIiLKJ5hgGCguVbdyMfFJ2RciIiIqZJhgGMjeTLdyLnaWxg2EiIgoH2KCYaCy9gJu9hbI7IkjMgDuDpao5+OYm2ERERHlC0wwDGQiA75pWwkANJKMjO3gDr6Qm/ChZ0REVPQwwciB1lVcsaR3bbg5qHeDuDlYYknv2viwqnseRUZERJS3TPM6gILuw6ruCPB1w7mIF4iJT4KLXXq3CFsuiIioKGOCIQG5iQz+ZZ3yOgwiIqJ8g10kREREJDkmGERERCQ5JhhEREQkOSYYREREJDkmGERERCQ5JhhEREQkuSI3TVWI9Menx8XFGXyN1NRUJCQkIC4uDmZmOj6UhLLFepUe61R6rFPjYL1Kzxh1mvHdmfFdmpUil2DEx8cDAEqVKpXHkRARERVM8fHxcHBwyLKMTOiShhQiSqUSjx8/hp2dHWQyw1bbjIuLQ6lSpfDvv//C3t5e4giLLtar9Fin0mOdGgfrVXrGqFMhBOLj4+Hh4QETk6xHWRS5FgwTExOULFlSkmvZ29vzF8EIWK/SY51Kj3VqHKxX6Uldp9m1XGTgIE8iIiKSHBMMIiIikhwTDANYWFggODgYFhYWeR1KocJ6lR7rVHqsU+NgvUovr+u0yA3yJCIiIuNjCwYRERFJjgkGERERSY4JBhEREUmOCQYRERFJjgmGARYvXgwfHx9YWlqiTp06OH78eF6HVGDMnj0bdevWhZ2dHVxcXNCpUyfcvn1brYwQAlOnToWHhwesrKzQrFkzXL9+PY8iLnhmz54NmUyG0aNHq/axTg3z6NEj9O7dG05OTrC2tkbNmjURHh6uOs561U9aWhq++eYb+Pj4wMrKCmXKlMG0adOgVCpVZVin2Tt27Bg6dOgADw8PyGQy7N69W+24LnWYnJyMUaNGwdnZGTY2NujYsSMePnwobaCC9LJlyxZhZmYmVqxYIW7cuCE+//xzYWNjIx48eJDXoRUIrVu3FqtXrxbXrl0Tly5dEu3atROlS5cWr1+/VpWZM2eOsLOzE//73//E1atXRffu3YW7u7uIi4vLw8gLhnPnzglvb29RvXp18fnnn6v2s0719+LFC+Hl5SX69+8vzp49KyIiIsSff/4p7t69qyrDetXPjBkzhJOTk/jtt99ERESE2L59u7C1tRULFixQlWGdZi80NFRMmjRJ/O9//xMAxK5du9SO61KHw4YNE56eniIsLExcuHBBNG/eXNSoUUOkpaVJFicTDD3Vq1dPDBs2TG1fpUqVxIQJE/IoooItJiZGABBHjx4VQgihVCqFm5ubmDNnjqpMUlKScHBwEEuXLs2rMAuE+Ph4Ub58eREWFiaaNm2qSjBYp4b56quvRKNGjTI9znrVX7t27cTAgQPV9nXu3Fn07t1bCME6NcT7CYYudfjq1SthZmYmtmzZoirz6NEjYWJiIvbt2ydZbOwi0UNKSgrCw8MRGBiotj8wMBCnTp3Ko6gKttjYWACAo6MjACAiIgLR0dFqdWxhYYGmTZuyjrMxYsQItGvXDq1atVLbzzo1zJ49e+Dn54dPPvkELi4uqFWrFlasWKE6znrVX6NGjXDw4EHcuXMHAHD58mWcOHECbdu2BcA6lYIudRgeHo7U1FS1Mh4eHqhataqk9VzkHnaWE8+ePYNCoYCrq6vafldXV0RHR+dRVAWXEAJjxoxBo0aNULVqVQBQ1aO2On7w4EGux1hQbNmyBRcuXMBff/2lcYx1aph79+5hyZIlGDNmDL7++mucO3cOn332GSwsLNC3b1/WqwG++uorxMbGolKlSpDL5VAoFJg5cyZ69OgBgO9VKehSh9HR0TA3N0fx4sU1ykj5XcYEwwDvP+ZdCGHwo9+LspEjR+LKlSs4ceKExjHWse7+/fdffP755zhw4AAsLS0zLcc61Y9SqYSfnx9mzZoFAKhVqxauX7+OJUuWoG/fvqpyrFfdbd26FRs2bMCmTZtQpUoVXLp0CaNHj4aHhwf69eunKsc6zTlD6lDqemYXiR6cnZ0hl8s1MryYmBiNbJGyNmrUKOzZsweHDx9GyZIlVfvd3NwAgHWsh/DwcMTExKBOnTowNTWFqakpjh49ip9++gmmpqaqemOd6sfd3R2+vr5q+ypXrozIyEgAfK8aYty4cZgwYQL+7//+D9WqVUOfPn3wxRdfYPbs2QBYp1LQpQ7d3NyQkpKCly9fZlpGCkww9GBubo46deogLCxMbX9YWBgaNGiQR1EVLEIIjBw5Ejt37sShQ4fg4+OjdtzHxwdubm5qdZySkoKjR4+yjjPRsmVLXL16FZcuXVL9+Pn5oVevXrh06RLKlCnDOjVAw4YNNaZQ37lzB15eXgD4XjVEQkICTEzUv3bkcrlqmirrNOd0qcM6derAzMxMrUxUVBSuXbsmbT1LNly0iMiYprpy5Upx48YNMXr0aGFjYyPu37+f16EVCMOHDxcODg7iyJEjIioqSvWTkJCgKjNnzhzh4OAgdu7cKa5evSp69OjBaWp6encWiRCsU0OcO3dOmJqaipkzZ4q///5bbNy4UVhbW4sNGzaoyrBe9dOvXz/h6empmqa6c+dO4ezsLMaPH68qwzrNXnx8vLh48aK4ePGiACDmz58vLl68qFouQZc6HDZsmChZsqT4888/xYULF0SLFi04TTU/WLRokfDy8hLm5uaidu3aqimWlD0AWn9Wr16tKqNUKkVwcLBwc3MTFhYWokmTJuLq1at5F3QB9H6CwTo1zN69e0XVqlWFhYWFqFSpkli+fLnacdarfuLi4sTnn38uSpcuLSwtLUWZMmXEpEmTRHJysqoM6zR7hw8f1vo52q9fPyGEbnWYmJgoRo4cKRwdHYWVlZVo3769iIyMlDROPq6diIiIJMcxGERERCQ5JhhEREQkOSYYREREJDkmGERERCQ5JhhEREQkOSYYREREJDkmGERERCQ5JhhEREQkOSYYRIXI/fv3IZPJcOnSpbwOReXWrVuoX78+LC0tUbNmzbwOh4hyCRMMIgn1798fMpkMc+bMUdu/e/fuIvu46eDgYNjY2OD27ds4ePBgpuWio6MxatQolClTBhYWFihVqhQ6dOiQ5TlFUf/+/dGpU6e8DoMoW0wwiCRmaWmJuXPnajwKuSBLSUkx+Nx//vkHjRo1gpeXF5ycnLSWuX//PurUqYNDhw5h3rx5uHr1Kvbt24fmzZtjxIgRBt+biPIOEwwiibVq1Qpubm6YPXt2pmWmTp2q0V2wYMECeHt7q7Yz/lKdNWsWXF1dUaxYMYSEhCAtLQ3jxo2Do6MjSpYsiVWrVmlc/9atW2jQoAEsLS1RpUoVHDlyRO34jRs30LZtW9ja2sLV1RV9+vTBs2fPVMebNWuGkSNHYsyYMXB2dkZAQIDW16FUKjFt2jSULFkSFhYWqFmzJvbt26c6LpPJEB4ejmnTpkEmk2Hq1KlarxMUFASZTIZz586ha9euqFChAqpUqYIxY8bgzJkzqnKRkZH46KOPYGtrC3t7e3Tr1g1PnjzRqNdVq1ahdOnSsLW1xfDhw6FQKDBv3jy4ubnBxcUFM2fOVLu/TCbDkiVL0KZNG1hZWcHHxwfbt29XK3P16lW0aNECVlZWcHJywqefforXr19r/Ht99913cHd3h5OTE0aMGIHU1FRVmZSUFIwfPx6enp6wsbHBBx98oPZvs2bNGhQrVgz79+9H5cqVYWtriw8//BBRUVGq17d27Vr8+uuvkMlkkMlkOHLkCFJSUjBy5Ei4u7vD0tIS3t7eWb7/iHKFpI9OIyri+vXrJz766COxc+dOYWlpKf79918hhBC7du0S7/66BQcHixo1aqid+8MPPwgvLy+1a9nZ2YkRI0aIW7duiZUrVwoAonXr1mLmzJnizp07Yvr06cLMzEz1FMSIiAgBQJQsWVLs2LFD3LhxQwwePFjY2dmJZ8+eCSGEePz4sXB2dhYTJ04UN2/eFBcuXBABAQGiefPmqns3bdpU2NrainHjxolbt26Jmzdvan298+fPF/b29mLz5s3i1q1bYvz48cLMzEzcuXNHCCFEVFSUqFKlihg7dqyIiooS8fHxGtd4/vy5kMlkYtasWVnWrVKpFLVq1RKNGjUS58+fF2fOnBG1a9cWTZs2VatXW1tb0bVrV3H9+nWxZ88eYW5uLlq3bi1GjRolbt26JVatWiUAiNOnT6vOAyCcnJzEihUrxO3bt8U333wj5HK5uHHjhhBCiDdv3ggPDw/RuXNncfXqVXHw4EHh4+Ojenplxr+Xvb29GDZsmLh586bYu3evsLa2VnsCa8+ePUWDBg3EsWPHxN27d8W3334rLCwsVPW1evVqYWZmJlq1aiX++usvER4eLipXrix69uwphEh/THe3bt3Ehx9+KKKiokRUVJRITk4W3377rShVqpQ4duyYuH//vjh+/LjYtGlTlvVJZGxMMIgklJFgCCFE/fr1xcCBA4UQhicYXl5eQqFQqPZVrFhRNG7cWLWdlpYmbGxsxObNm4UQbxOMOXPmqMqkpqaKkiVLirlz5wohhJg8ebIIDAxUu/e///4rAIjbt28LIdITjJo1a2b7ej08PMTMmTPV9tWtW1cEBQWptmvUqCGCg4MzvcbZs2cFALFz584s73XgwAEhl8vVHil9/fp1AUCcO3dOCJFer9bW1iIuLk5VpnXr1sLb21ujHmfPnq3aBiCGDRumdr8PPvhADB8+XAghxPLly0Xx4sXF69evVcd///13YWJiIqKjo4UQb/+90tLSVGU++eQT0b17dyGEEHfv3hUymUw8evRI7T4tW7YUEydOFEKkJxgAxN27d1XHFy1aJFxdXVXb777HMowaNUq0aNFCKJXKTOuPKLexi4TISObOnYu1a9fixo0bBl+jSpUqMDF5+2vq6uqKatWqqbblcjmcnJwQExOjdp6/v7/qv01NTeHn54ebN28CAMLDw3H48GHY2tqqfipVqgQgfbxEBj8/vyxji4uLw+PHj9GwYUO1/Q0bNlTdSxdCCADIdhDszZs3UapUKZQqVUq1z9fXF8WKFVO7n7e3N+zs7FTbrq6u8PX11ajHrOosYzvjujdv3kSNGjVgY2OjOt6wYUMolUrcvn1bta9KlSqQy+WqbXd3d9V9Lly4ACEEKlSooFb3R48eVat3a2trlC1bVus1MtO/f39cunQJFStWxGeffYYDBw5kWZ4oN5jmdQBEhVWTJk3QunVrfP311+jfv7/aMRMTE9UXa4Z3++ozmJmZqW3LZDKt+5RKZbbxZHyBK5VKdOjQAXPnztUo4+7urvrvd79MdbluBiGEXjNmypcvD5lMhps3b2Y5OyKz676/3xh1ltVryu7eGfdRKpWQy+UIDw9XS0IAwNbWNstrvP9eeV/t2rURERGBP/74A3/++Se6deuGVq1aYceOHdm8QiLjYQsGkRHNmTMHe/fuxalTp9T2lyhRAtHR0WpfHFKuXfHuwMi0tDSEh4erWilq166N69evw9vbG+XKlVP70TWpAAB7e3t4eHjgxIkTavtPnTqFypUr63wdR0dHtG7dGosWLcKbN280jr969QpAemtFZGQk/v33X9WxGzduIDY2Vq/7ZebdOsvYzqgzX19fXLp0SS2+kydPwsTEBBUqVNDp+rVq1YJCoUBMTIxGvbu5uekcp7m5ORQKhcZ+e3t7dO/eHStWrMDWrVvxv//9Dy9evND5ukRSY4JBZETVqlVDr169sHDhQrX9zZo1w9OnTzFv3jz8888/WLRoEf744w/J7rto0SLs2rULt27dwogRI/Dy5UsMHDgQADBixAi8ePECPXr0wLlz53Dv3j0cOHAAAwcO1PrFlZVx48Zh7ty52Lp1K27fvo0JEybg0qVL+Pzzz/W6zuLFi6FQKFCvXj3873//w99//42bN2/ip59+UnVdtGrVCtWrV0evXr1w4cIFnDt3Dn379kXTpk2z7c7Rxfbt27Fq1SrcuXMHwcHBOHfuHEaOHAkA6NWrFywtLdGvXz9cu3YNhw8fxqhRo9CnTx+4urrqdP0KFSqgV69e6Nu3L3bu3ImIiAj89ddfmDt3LkJDQ3WO09vbG1euXMHt27fx7NkzpKam4ocffsCWLVtw69Yt3LlzB9u3b4ebmxuKFStmSFUQSYIJBpGRTZ8+XaOJu3Llyli8eDEWLVqEGjVq4Ny5c/jyyy8lu+ecOXMwd+5c1KhRA8ePH8evv/4KZ2dnAICHhwdOnjwJhUKB1q1bo2rVqvj888/h4OCgNk5BF5999hnGjh2LsWPHolq1ati3bx/27NmD8uXL63UdHx8fXLhwAc2bN8fYsWNRtWpVBAQE4ODBg1iyZAmA9K6C3bt3o3jx4mjSpAlatWqFMmXKYOvWrXrdKzMhISHYsmULqlevjrVr12Ljxo3w9fUFkD4uYv/+/Xjx4gXq1q2Lrl27omXLlvj555/1usfq1avRt29fjB07FhUrVkTHjh1x9uxZtXEl2RkyZAgqVqwIPz8/lChRAidPnoStrS3mzp0LPz8/1K1bF/fv30doaKje/55EUpKJ7Dr3iIgKOZlMhl27dnGFTCIJMb0lIiIiyTHBICIiIslxmioRFXnsKSaSHlswiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhy/w+ovyRJcHLYngAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Stack your training embeddings into an (N × D) matrix\n",
    "X_train = np.vstack(train_df[\"Embedding\"].values)   # shape: (100, D)\n",
    "\n",
    "# 2) Fit an “untruncated” PCA to get all eigenvalues\n",
    "pca_full = PCA(random_state=0)\n",
    "pca_full.fit(X_train)\n",
    "\n",
    "# 3) Extract the raw eigenvalues (not the explained-variance ratios)\n",
    "eigenvalues = pca_full.explained_variance_          # length = min(N,D)\n",
    "\n",
    "# 4) Cumulative explained variance\n",
    "cum_ev = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(\n",
    "    np.arange(1, len(cum_ev)+1),\n",
    "    cum_ev,\n",
    "    marker='o', linestyle='-'\n",
    ")\n",
    "plt.axhline(0.90, color='r', linestyle='--', label='90% explained')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid MSE (PCA): 0.1508865787637614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_Name</th>\n",
       "      <th>Average_Human_Response</th>\n",
       "      <th>Question</th>\n",
       "      <th>Average_LLM_Response</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Debiased_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abfirm</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>How firm are you about your opinion on abortio...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[0.0027009211480617523, -0.004779394716024399,...</td>\n",
       "      <td>3.705255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natchld</td>\n",
       "      <td>1.496186</td>\n",
       "      <td>We are faced with many problems in this countr...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.032813724130392075, -0.015181060880422592, ...</td>\n",
       "      <td>1.237994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawimp</td>\n",
       "      <td>1.716904</td>\n",
       "      <td>How important is the law enforcement issue to ...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.005202507134526968, -0.008557395078241825, ...</td>\n",
       "      <td>1.723790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marhisp</td>\n",
       "      <td>2.643818</td>\n",
       "      <td>What about having a close relative marry a Jew...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>[-0.011182423681020737, 0.007882031612098217, ...</td>\n",
       "      <td>2.503659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conbus</td>\n",
       "      <td>1.934551</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.03869510814547539, -0.029890233650803566, 0...</td>\n",
       "      <td>1.928694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>life</td>\n",
       "      <td>1.587822</td>\n",
       "      <td>In general, do you find life exciting, pretty ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.012269247323274612, -0.015354420989751816,...</td>\n",
       "      <td>1.139519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>letineur</td>\n",
       "      <td>3.398006</td>\n",
       "      <td>What about the number of immigrants from Europ...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[-0.022011730819940567, 0.00751867052167654, 0...</td>\n",
       "      <td>3.093710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alienat1</td>\n",
       "      <td>1.465340</td>\n",
       "      <td>Now I want to read you some things some people...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.023283887654542923, 0.01102173700928688, -0...</td>\n",
       "      <td>1.173483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hapcohab</td>\n",
       "      <td>1.458306</td>\n",
       "      <td>Taking things all together, would you say that...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.008415235206484795, -0.058157648891210556,...</td>\n",
       "      <td>1.058514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>conclerg</td>\n",
       "      <td>1.964817</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.023766914382576942, -0.022856036201119423, ...</td>\n",
       "      <td>2.045277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_Name  Average_Human_Response  \\\n",
       "0        abfirm                3.428571   \n",
       "1       natchld                1.496186   \n",
       "2        lawimp                1.716904   \n",
       "3       marhisp                2.643818   \n",
       "4        conbus                1.934551   \n",
       "5          life                1.587822   \n",
       "6      letineur                3.398006   \n",
       "7      alienat1                1.465340   \n",
       "8      hapcohab                1.458306   \n",
       "9      conclerg                1.964817   \n",
       "\n",
       "                                            Question  Average_LLM_Response  \\\n",
       "0  How firm are you about your opinion on abortio...              4.000000   \n",
       "1  We are faced with many problems in this countr...              1.166667   \n",
       "2  How important is the law enforcement issue to ...              2.000000   \n",
       "3  What about having a close relative marry a Jew...              2.666667   \n",
       "4  I am going to name some institutions in this c...              2.000000   \n",
       "5  In general, do you find life exciting, pretty ...              1.000000   \n",
       "6  What about the number of immigrants from Europ...              3.000000   \n",
       "7  Now I want to read you some things some people...              1.166667   \n",
       "8  Taking things all together, would you say that...              1.000000   \n",
       "9  I am going to name some institutions in this c...              2.000000   \n",
       "\n",
       "                                           Embedding  Debiased_Response  \n",
       "0  [0.0027009211480617523, -0.004779394716024399,...           3.705255  \n",
       "1  [0.032813724130392075, -0.015181060880422592, ...           1.237994  \n",
       "2  [0.005202507134526968, -0.008557395078241825, ...           1.723790  \n",
       "3  [-0.011182423681020737, 0.007882031612098217, ...           2.503659  \n",
       "4  [0.03869510814547539, -0.029890233650803566, 0...           1.928694  \n",
       "5  [-0.012269247323274612, -0.015354420989751816,...           1.139519  \n",
       "6  [-0.022011730819940567, 0.00751867052167654, 0...           3.093710  \n",
       "7  [0.023283887654542923, 0.01102173700928688, -0...           1.173483  \n",
       "8  [-0.008415235206484795, -0.058157648891210556,...           1.058514  \n",
       "9  [0.023766914382576942, -0.022856036201119423, ...           2.045277  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA‐based\n",
    "beta_pca, mse_pca, pca_model = fit_beta_pca_penalty(train_df.copy(), n_components=50, penalty_coef=20.0)\n",
    "Xv = pca_model.transform(np.vstack(valid_df[\"Embedding\"].values))\n",
    "valid_df[\"Debiased_Response\"] = valid_df[\"Average_LLM_Response\"].to_numpy() - Xv.dot(beta_pca)\n",
    "mse_val_pca = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "print(\"Valid MSE (PCA):\", mse_val_pca)\n",
    "selected_df = valid_df.loc[keep_idx].reset_index(drop=True)\n",
    "selected_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid MSE (FA): 0.13708485034567763\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_Name</th>\n",
       "      <th>Average_Human_Response</th>\n",
       "      <th>Question</th>\n",
       "      <th>Average_LLM_Response</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Debiased_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abfirm</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>How firm are you about your opinion on abortio...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[0.0027009211480617523, -0.004779394716024399,...</td>\n",
       "      <td>3.419069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natchld</td>\n",
       "      <td>1.496186</td>\n",
       "      <td>We are faced with many problems in this countr...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.032813724130392075, -0.015181060880422592, ...</td>\n",
       "      <td>1.225269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawimp</td>\n",
       "      <td>1.716904</td>\n",
       "      <td>How important is the law enforcement issue to ...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.005202507134526968, -0.008557395078241825, ...</td>\n",
       "      <td>1.460936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marhisp</td>\n",
       "      <td>2.643818</td>\n",
       "      <td>What about having a close relative marry a Jew...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>[-0.011182423681020737, 0.007882031612098217, ...</td>\n",
       "      <td>2.347552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conbus</td>\n",
       "      <td>1.934551</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.03869510814547539, -0.029890233650803566, 0...</td>\n",
       "      <td>1.901836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>life</td>\n",
       "      <td>1.587822</td>\n",
       "      <td>In general, do you find life exciting, pretty ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.012269247323274612, -0.015354420989751816,...</td>\n",
       "      <td>1.316262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>letineur</td>\n",
       "      <td>3.398006</td>\n",
       "      <td>What about the number of immigrants from Europ...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[-0.022011730819940567, 0.00751867052167654, 0...</td>\n",
       "      <td>3.164949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alienat1</td>\n",
       "      <td>1.465340</td>\n",
       "      <td>Now I want to read you some things some people...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[0.023283887654542923, 0.01102173700928688, -0...</td>\n",
       "      <td>1.340258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hapcohab</td>\n",
       "      <td>1.458306</td>\n",
       "      <td>Taking things all together, would you say that...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.008415235206484795, -0.058157648891210556,...</td>\n",
       "      <td>1.063389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>conclerg</td>\n",
       "      <td>1.964817</td>\n",
       "      <td>I am going to name some institutions in this c...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[0.023766914382576942, -0.022856036201119423, ...</td>\n",
       "      <td>2.094103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_Name  Average_Human_Response  \\\n",
       "0        abfirm                3.428571   \n",
       "1       natchld                1.496186   \n",
       "2        lawimp                1.716904   \n",
       "3       marhisp                2.643818   \n",
       "4        conbus                1.934551   \n",
       "5          life                1.587822   \n",
       "6      letineur                3.398006   \n",
       "7      alienat1                1.465340   \n",
       "8      hapcohab                1.458306   \n",
       "9      conclerg                1.964817   \n",
       "\n",
       "                                            Question  Average_LLM_Response  \\\n",
       "0  How firm are you about your opinion on abortio...              4.000000   \n",
       "1  We are faced with many problems in this countr...              1.166667   \n",
       "2  How important is the law enforcement issue to ...              2.000000   \n",
       "3  What about having a close relative marry a Jew...              2.666667   \n",
       "4  I am going to name some institutions in this c...              2.000000   \n",
       "5  In general, do you find life exciting, pretty ...              1.000000   \n",
       "6  What about the number of immigrants from Europ...              3.000000   \n",
       "7  Now I want to read you some things some people...              1.166667   \n",
       "8  Taking things all together, would you say that...              1.000000   \n",
       "9  I am going to name some institutions in this c...              2.000000   \n",
       "\n",
       "                                           Embedding  Debiased_Response  \n",
       "0  [0.0027009211480617523, -0.004779394716024399,...           3.419069  \n",
       "1  [0.032813724130392075, -0.015181060880422592, ...           1.225269  \n",
       "2  [0.005202507134526968, -0.008557395078241825, ...           1.460936  \n",
       "3  [-0.011182423681020737, 0.007882031612098217, ...           2.347552  \n",
       "4  [0.03869510814547539, -0.029890233650803566, 0...           1.901836  \n",
       "5  [-0.012269247323274612, -0.015354420989751816,...           1.316262  \n",
       "6  [-0.022011730819940567, 0.00751867052167654, 0...           3.164949  \n",
       "7  [0.023283887654542923, 0.01102173700928688, -0...           1.340258  \n",
       "8  [-0.008415235206484795, -0.058157648891210556,...           1.063389  \n",
       "9  [0.023766914382576942, -0.022856036201119423, ...           2.094103  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA‐based\n",
    "beta_fa, mse_fa, fa_model = fit_beta_factor_penalty(train_df.copy(), n_components=50, penalty_coef=20.0)\n",
    "Xv_fa = fa_model.transform(np.vstack(valid_df[\"Embedding\"].values))\n",
    "valid_df[\"Debiased_Response\"] = valid_df[\"Average_LLM_Response\"].to_numpy() - Xv_fa.dot(beta_fa)\n",
    "mse_val_fa = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "print(\"Valid MSE (FA):\", mse_val_fa)\n",
    "selected_df = valid_df.loc[keep_idx].reset_index(drop=True)\n",
    "selected_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4047\n",
      "Validation MSE: 0.4351917695028266\n",
      "Valid MSE (PCA): 0.5178581906379968\n",
      "Valid MSE (FA): 0.4626747580751937\n",
      "9415\n",
      "Validation MSE: 1.256509586074197\n",
      "Valid MSE (PCA): 1.2188123726385827\n",
      "Valid MSE (FA): 0.9474821357016237\n",
      "9624\n",
      "Validation MSE: 0.6742240423011244\n",
      "Valid MSE (PCA): 0.6342093579190974\n",
      "Valid MSE (FA): 0.6481571288334861\n",
      "8987\n",
      "Validation MSE: 0.3638836335171227\n",
      "Valid MSE (PCA): 0.504544099286027\n",
      "Valid MSE (FA): 0.6871484707272929\n",
      "1779\n",
      "Validation MSE: 0.3618398442646787\n",
      "Valid MSE (PCA): 0.30531722260762667\n",
      "Valid MSE (FA): 0.48982789044708985\n",
      "143\n",
      "Validation MSE: 0.3805280657604546\n",
      "Valid MSE (PCA): 0.44307956922521163\n",
      "Valid MSE (FA): 0.4923142405502358\n",
      "200\n",
      "Validation MSE: 0.4567410142072303\n",
      "Valid MSE (PCA): 0.6697417858323522\n",
      "Valid MSE (FA): 0.9047628359537169\n",
      "8932\n",
      "Validation MSE: 0.6601207810940517\n",
      "Valid MSE (PCA): 0.7289368554508209\n",
      "Valid MSE (FA): 0.8844843204078109\n",
      "6458\n",
      "Validation MSE: 0.3090394962061997\n",
      "Valid MSE (PCA): 0.3342332807241772\n",
      "Valid MSE (FA): 0.43765360502555445\n",
      "242\n",
      "Validation MSE: 0.7604771679402189\n",
      "Valid MSE (PCA): 0.8060718338774139\n",
      "Valid MSE (FA): 0.7801866580156521\n",
      "5119\n",
      "Validation MSE: 0.7798300834756761\n",
      "Valid MSE (PCA): 0.7421498274225158\n",
      "Valid MSE (FA): 1.0748535709454634\n",
      "6127\n",
      "Validation MSE: 0.37534974482974687\n",
      "Valid MSE (PCA): 0.3807830968567587\n",
      "Valid MSE (FA): 0.6141362336722493\n",
      "9316\n",
      "Validation MSE: 0.3275471606722669\n",
      "Valid MSE (PCA): 0.4720296826768134\n",
      "Valid MSE (FA): 0.6371181853350537\n",
      "7176\n",
      "Validation MSE: 0.61506274419662\n",
      "Valid MSE (PCA): 0.7011706073061283\n",
      "Valid MSE (FA): 0.7467621838407944\n",
      "8665\n",
      "Validation MSE: 0.5462876718531137\n",
      "Valid MSE (PCA): 0.45316086233353126\n",
      "Valid MSE (FA): 0.6636165930617929\n",
      "2483\n",
      "Validation MSE: 1.218679416146247\n",
      "Valid MSE (PCA): 0.9212713156071627\n",
      "Valid MSE (FA): 0.9530351804538767\n",
      "9997\n",
      "Validation MSE: 0.2994213836163289\n",
      "Valid MSE (PCA): 0.342161306668008\n",
      "Valid MSE (FA): 0.2789357410391871\n",
      "2062\n",
      "Validation MSE: 0.6649346060604355\n",
      "Valid MSE (PCA): 0.7460315997251441\n",
      "Valid MSE (FA): 0.8935428551230714\n",
      "8950\n",
      "Validation MSE: 1.4647335386145162\n",
      "Valid MSE (PCA): 1.4295773038919588\n",
      "Valid MSE (FA): 1.275094021500285\n",
      "9476\n",
      "Validation MSE: 0.6168890208413845\n",
      "Valid MSE (PCA): 0.6390384248441595\n",
      "Valid MSE (FA): 0.6428501039692688\n",
      "187\n",
      "Validation MSE: 0.5780323621221303\n",
      "Valid MSE (PCA): 0.5373954755216941\n",
      "Valid MSE (FA): 0.667945039962574\n",
      "2611\n",
      "Validation MSE: 1.1273080093148333\n",
      "Valid MSE (PCA): 1.1477600463801818\n",
      "Valid MSE (FA): 1.0993452696469062\n",
      "7363\n",
      "Validation MSE: 1.4187591346868356\n",
      "Valid MSE (PCA): 1.402951842144873\n",
      "Valid MSE (FA): 1.4894730426928986\n",
      "2820\n",
      "Validation MSE: 0.3789655348287693\n",
      "Valid MSE (PCA): 0.43234591489829904\n",
      "Valid MSE (FA): 0.7137473827399824\n",
      "5478\n",
      "Validation MSE: 1.3827063777625161\n",
      "Valid MSE (PCA): 1.4247877187078497\n",
      "Valid MSE (FA): 1.5573863773888996\n",
      "5881\n",
      "Validation MSE: 0.5931185250482925\n",
      "Valid MSE (PCA): 0.6581021059715427\n",
      "Valid MSE (FA): 0.6770827532005851\n",
      "8587\n",
      "Validation MSE: 0.48875887947789715\n",
      "Valid MSE (PCA): 0.5050641770024605\n",
      "Valid MSE (FA): 0.5366249648563354\n",
      "7746\n",
      "Validation MSE: 0.31468637894499346\n",
      "Valid MSE (PCA): 0.341584898065214\n",
      "Valid MSE (FA): 0.34140795051738976\n",
      "1775\n",
      "Validation MSE: 0.4288568840422959\n",
      "Valid MSE (PCA): 0.5631245201241564\n",
      "Valid MSE (FA): 0.8542267263852201\n",
      "3214\n",
      "Validation MSE: 0.7984160072142349\n",
      "Valid MSE (PCA): 0.6648516304944445\n",
      "Valid MSE (FA): 0.7647185401644232\n",
      "46\n",
      "Validation MSE: 0.23379825031734205\n",
      "Valid MSE (PCA): 0.316437077825697\n",
      "Valid MSE (FA): 0.4497257663514998\n",
      "858\n",
      "Validation MSE: 0.4388720307848953\n",
      "Valid MSE (PCA): 0.5783204545825406\n",
      "Valid MSE (FA): 0.6815149319809537\n",
      "3907\n",
      "Validation MSE: 1.4261481127361826\n",
      "Valid MSE (PCA): 1.553729482592514\n",
      "Valid MSE (FA): 1.4665890936755144\n",
      "8733\n",
      "Validation MSE: 0.502136513963401\n",
      "Valid MSE (PCA): 0.6198321684555844\n",
      "Valid MSE (FA): 0.4988796850026505\n",
      "6536\n",
      "Validation MSE: 1.0595577197694837\n",
      "Valid MSE (PCA): 1.2547332986619093\n",
      "Valid MSE (FA): 1.3356051229093182\n",
      "8221\n",
      "Validation MSE: 0.4327504609458435\n",
      "Valid MSE (PCA): 0.5238529419678967\n",
      "Valid MSE (FA): 0.5718918040800421\n",
      "3069\n",
      "Validation MSE: 0.7894985596558229\n",
      "Valid MSE (PCA): 0.7144605501612213\n",
      "Valid MSE (FA): 0.8965081341474708\n",
      "2681\n",
      "Validation MSE: 0.7210702884364105\n",
      "Valid MSE (PCA): 0.6563273117354927\n",
      "Valid MSE (FA): 0.8545232781974405\n",
      "8769\n",
      "Validation MSE: 0.3704220560451414\n",
      "Valid MSE (PCA): 0.3591667978960804\n",
      "Valid MSE (FA): 0.4156875352986597\n",
      "2946\n",
      "Validation MSE: 2.9667340476944655\n",
      "Valid MSE (PCA): 3.244650729326908\n",
      "Valid MSE (FA): 3.3919842089551175\n",
      "7316\n",
      "Validation MSE: 0.6142132960208911\n",
      "Valid MSE (PCA): 0.7727455378162557\n",
      "Valid MSE (FA): 1.2607007456606545\n",
      "8990\n",
      "Validation MSE: 0.35250205892770387\n",
      "Valid MSE (PCA): 0.4379834150503838\n",
      "Valid MSE (FA): 0.4187225345210246\n",
      "9058\n",
      "Validation MSE: 0.35011163498134307\n",
      "Valid MSE (PCA): 0.46091516440131636\n",
      "Valid MSE (FA): 0.34893520130506034\n",
      "5235\n",
      "Validation MSE: 0.2131465027953865\n",
      "Valid MSE (PCA): 0.3119105651772056\n",
      "Valid MSE (FA): 0.36024837178774055\n",
      "8566\n",
      "Validation MSE: 0.22868321909503128\n",
      "Valid MSE (PCA): 0.1508865787637614\n",
      "Valid MSE (FA): 0.14948875430235323\n",
      "4976\n",
      "Validation MSE: 0.24030893377783\n",
      "Valid MSE (PCA): 0.3267754302388799\n",
      "Valid MSE (FA): 0.38315270037973187\n",
      "6622\n",
      "Validation MSE: 0.3599717024688272\n",
      "Valid MSE (PCA): 0.6092724561128481\n",
      "Valid MSE (FA): 0.92501925682423\n",
      "5479\n",
      "Validation MSE: 0.36017314828691394\n",
      "Valid MSE (PCA): 0.44598816316248113\n",
      "Valid MSE (FA): 0.5211911602375495\n",
      "8698\n",
      "Validation MSE: 0.27513476592428926\n",
      "Valid MSE (PCA): 0.32695242209021397\n",
      "Valid MSE (FA): 0.436516453752923\n",
      "5574\n",
      "Validation MSE: 0.37012041775483917\n",
      "Valid MSE (PCA): 0.5175235521460986\n",
      "Valid MSE (FA): 0.6598885435547798\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file (with embeddings as lists)\n",
    "df = pd.read_pickle(\"survey_with_embeddings.pkl\")\n",
    "\n",
    "seeds = [secrets.randbelow(10000) for _ in range(50)]\n",
    "for seed in seeds:\n",
    "    print(seed)\n",
    "    # this will randomly select 100 rows for train, and the other 12 for valid\n",
    "    train_df, valid_df = train_test_split(\n",
    "        df,\n",
    "        train_size=100,\n",
    "        random_state=seed,   # for reproducibility\n",
    "        shuffle=True\n",
    "    )\n",
    "    # print(train_df.shape)  # (100, )\n",
    "    # print(valid_df.shape)  # (12, )\n",
    "    # print(\"Embedding shape:\", len(df[\"Embedding\"].iloc[0]))\n",
    "\n",
    "    # your list of regularization strengths\n",
    "    lambdas = [1.0, 5.0]\n",
    "\n",
    "    # a place to collect (lambda, mse, beta) tuples\n",
    "    results = []\n",
    "\n",
    "    for lam in lambdas:\n",
    "        # fit on a fresh copy so we don't overwrite Debiased_Response repeatedly\n",
    "        beta_hat, mse_train = fit_beta(train_df.copy(), lambda_ridge=lam)\n",
    "        \n",
    "        # print out for quick console feedback\n",
    "        # print(f\"λ={lam:>5} → train MSE = {mse_train:.4f}\")\n",
    "        \n",
    "        # record into our list\n",
    "        results.append({\n",
    "            \"lambda\":        lam,\n",
    "            \"mse_train\":     mse_train,\n",
    "            \"beta_hat\":      beta_hat  # this is a length-d numpy array\n",
    "        })\n",
    "        \n",
    "    # get embeddings matrix on valid\n",
    "    X_val = np.vstack(valid_df[\"Embedding\"].values)\n",
    "    # raw llm\n",
    "    y_llm = valid_df[\"Average_LLM_Response\"].to_numpy()\n",
    "    # corrected\n",
    "    valid_df[\"Debiased_Response\"] = y_llm - X_val.dot(results[1]['beta_hat'])\n",
    "\n",
    "    # evaluate on valid\n",
    "    mse_valid = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "    print(\"Validation MSE:\", mse_valid)\n",
    "\n",
    "    # PCA‐based\n",
    "    beta_pca, mse_pca, pca_model = fit_beta_pca_penalty(train_df.copy(), n_components=50, penalty_coef=20.0)\n",
    "    Xv = pca_model.transform(np.vstack(valid_df[\"Embedding\"].values))\n",
    "    valid_df[\"Debiased_Response\"] = valid_df[\"Average_LLM_Response\"].to_numpy() - Xv.dot(beta_pca)\n",
    "    mse_val_pca = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "    print(\"Valid MSE (PCA):\", mse_val_pca)\n",
    "\n",
    "    # FA‐based\n",
    "    beta_fa, mse_fa, fa_model = fit_beta_factor_penalty(train_df.copy(), n_components=50, penalty_coef=50.0)\n",
    "    Xv_fa = fa_model.transform(np.vstack(valid_df[\"Embedding\"].values))\n",
    "    valid_df[\"Debiased_Response\"] = valid_df[\"Average_LLM_Response\"].to_numpy() - Xv_fa.dot(beta_fa)\n",
    "    mse_val_fa = np.mean((valid_df[\"Debiased_Response\"] - valid_df[\"Average_Human_Response\"].to_numpy())**2)\n",
    "    print(\"Valid MSE (FA):\", mse_val_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9997 5235 8566"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
