{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2bf3e-f988-46a3-b6c3-ed7fd2f5773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princess/.local/lib/python3.12/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Flow.__init__() got an unexpected keyword argument 'agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 206\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurvey_dict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m survey_dict\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m survey_dict\n\u001b[0;32m--> 206\u001b[0m flow \u001b[38;5;241m=\u001b[39m SurveyFlow(\n\u001b[1;32m    207\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[convert_agent, editor_agent],\n\u001b[1;32m    208\u001b[0m     tasks\u001b[38;5;241m=\u001b[39m[convert_task, research_task, improve_task],\n\u001b[1;32m    209\u001b[0m     process\u001b[38;5;241m=\u001b[39mProcess\u001b[38;5;241m.\u001b[39msequential,\n\u001b[1;32m    210\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msurvey_dict_to_qualtrics_payload\u001b[39m(survey_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Flow.__init__() got an unexpected keyword argument 'agents'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Union, Literal, Optional\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from crewai import Agent, Task, Crew, Flow, Process\n",
    "from crewai.flow.flow import start\n",
    "from crewai.tasks.task_output import OutputFormat\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "logging.getLogger(\"opentelemetry\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "os.environ[\"OTEL_TRACES_EXPORTER\"] = \"none\"\n",
    "\n",
    "# ========== Pydantic Models ==========\n",
    "class ChoiceOption(BaseModel):\n",
    "    text: str\n",
    "    value: str\n",
    "\n",
    "class ChoiceConfig(BaseModel):\n",
    "    options: List[ChoiceOption]\n",
    "\n",
    "class SliderConfig(BaseModel):\n",
    "    min: float\n",
    "    max: float\n",
    "    step: float\n",
    "\n",
    "class TextInputConfig(BaseModel):\n",
    "    placeholder: Optional[str] = None\n",
    "    multiline: bool = False\n",
    "\n",
    "class Question(BaseModel):\n",
    "    question_id: str\n",
    "    question_text: str\n",
    "    input_type: Literal[\"multiple_choice\", \"single_choice\", \"slider\", \"text_input\"]\n",
    "    input_config: Union[ChoiceConfig, SliderConfig, TextInputConfig]\n",
    "\n",
    "class Survey(BaseModel):\n",
    "    theme: str\n",
    "    purpose: str\n",
    "    questions: List[Question]\n",
    "\n",
    "class QuestionComment(BaseModel):\n",
    "    question_id: str\n",
    "    comment: str\n",
    "\n",
    "class AnnotatedSurvey(BaseModel):\n",
    "    survey: Survey\n",
    "    question_comments: List[QuestionComment]\n",
    "    overall_comment: Optional[str]\n",
    "\n",
    "class SurveyImprovementResult(BaseModel):\n",
    "    original_with_comments: AnnotatedSurvey\n",
    "    revised_survey: Survey\n",
    "\n",
    "# ========== Utility to load YAML ==========\n",
    "def load_yaml(path: str) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "# ========== Agent Definitions ==========\n",
    "conv_cfg = load_yaml(\"config/agents/survey_convert_agent.yaml\")[\"survey_convert_agent\"]\n",
    "convert_agent = Agent(\n",
    "    name=\"survey_convert_agent\",\n",
    "    role=conv_cfg[\"role\"],\n",
    "    goal=conv_cfg[\"goal\"],\n",
    "    backstory=conv_cfg[\"backstory\"],\n",
    "    verbose=conv_cfg[\"verbose\"],\n",
    "    allow_delegation=conv_cfg[\"allow_delegation\"]\n",
    ")\n",
    "\n",
    "edit_cfg = load_yaml(\"config/agents/survey_editor.yaml\")[\"survey_editor\"]\n",
    "editor_agent = Agent(\n",
    "    name=\"survey_editor_agent\",\n",
    "    role=edit_cfg[\"role\"],\n",
    "    goal=edit_cfg[\"goal\"],\n",
    "    backstory=edit_cfg[\"backstory\"],\n",
    "    verbose=edit_cfg[\"verbose\"],\n",
    "    allow_delegation=edit_cfg[\"allow_delegation\"]\n",
    ")\n",
    "\n",
    "# ========== Task Definitions ==========\n",
    "conv_t = load_yaml(\"config/tasks/convert_survey_to_json.yaml\")[\"convert_survey_to_json\"]\n",
    "convert_task = Task(\n",
    "    name=\"convert_survey_to_json\",\n",
    "    description=conv_t[\"description\"],\n",
    "    agent=convert_agent,\n",
    "    tool=conv_t.get(\"tool\"),\n",
    "    inputs=list(conv_t.get(\"inputs\", {}).keys()),\n",
    "    outputs=list(conv_t.get(\"outputs\", {}).keys()),\n",
    "    expected_output=conv_t[\"expected_output\"],\n",
    "    output_format=OutputFormat.JSON\n",
    ")\n",
    "\n",
    "res_t = load_yaml(\"config/tasks/apply_survey_enhancements.yaml\")[\"research_task\"]\n",
    "research_task = Task(\n",
    "    name=\"research_task\",\n",
    "    description=res_t[\"description\"],\n",
    "    agent=convert_agent,\n",
    "    inputs=list(res_t.get(\"inputs\", {}).keys()),\n",
    "    outputs=list(res_t.get(\"outputs\", {}).keys()),\n",
    "    expected_output=res_t[\"expected_output\"],\n",
    "    output_format=OutputFormat.JSON\n",
    ")\n",
    "\n",
    "imp_t = load_yaml(\"config/tasks/apply_survey_enhancements.yaml\")[\"improve_survey\"]\n",
    "improve_task = Task(\n",
    "    name=\"improve_survey\",\n",
    "    description=imp_t[\"description\"],\n",
    "    agent=editor_agent,\n",
    "    inputs=list(imp_t.get(\"inputs\", {}).keys()),\n",
    "    outputs=list(imp_t.get(\"outputs\", {}).keys()),\n",
    "    expected_output=imp_t[\"expected_output\"],\n",
    "    output_format=OutputFormat.JSON\n",
    ")\n",
    "\n",
    "# ========== Crew Definition ==========\n",
    "survey_crew = Crew(\n",
    "    agents=[convert_agent, editor_agent],\n",
    "    tasks=[convert_task, research_task, improve_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "class SurveyFlow(Flow):\n",
    "    @start()\n",
    "    def initial_run(self):\n",
    "        survey_text = self.state['survey_text'].strip()\n",
    "        first_line = survey_text.splitlines()[0]\n",
    "        topic = first_line.replace('Topic:', '').strip()\n",
    "        current_year = datetime.now().year\n",
    "\n",
    "\n",
    "        crew_result = survey_crew.kickoff(\n",
    "            inputs={\n",
    "                'survey_text': survey_text,\n",
    "                'topic': topic,\n",
    "                'current_year': current_year\n",
    "            }\n",
    "        )\n",
    "\n",
    "    \n",
    "        raw = crew_result.raw.strip()\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = raw.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0]\n",
    "    \n",
    "        survey_dict = json.loads(raw)\n",
    "        # validated = SurveyImprovementResult.parse_obj({\n",
    "        #     \"original_with_comments\": survey_dict[\"original_with_comments\"],\n",
    "        #     \"revised_survey\":         survey_dict[\"revised_survey\"]\n",
    "        # })\n",
    "\n",
    "        raw = crew_result.raw.strip()\n",
    "        if raw.startswith('```') and raw.endswith('```'):\n",
    "            raw = raw.split('\\n', 1)[1].rsplit('```', 1)[0]\n",
    "        try:\n",
    "            survey_dict = json.loads(raw)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"解析 JSON 失败: {e}\\nRaw output:\\n{raw}\")\n",
    "\n",
    "        # Pretty-print the original survey with comments\n",
    "        annotated = survey_dict.get('original_with_comments', {})\n",
    "        survey = annotated.get('survey', {})\n",
    "        comments = annotated.get('question_comments', [])\n",
    "        print(\"\\n=== Original Survey (with comments) ===\")\n",
    "        print(f\"Theme: {survey.get('theme', '')}\")\n",
    "        print(f\"Purpose: {survey.get('purpose', '')}\\n\")\n",
    "        for q in survey.get('questions', []):\n",
    "            qid = q.get('question_id')\n",
    "            print(f\"Question {qid}: {q.get('question_text')}\")\n",
    "            comment = next((c['comment'] for c in comments if c['question_id'] == qid), None)\n",
    "            if comment:\n",
    "                print(f\"  Comment: {comment}\")\n",
    "            print()\n",
    "        overall = annotated.get('overall_comment')\n",
    "        if overall:\n",
    "            print(f\"Overall comment: {overall}\\n\")\n",
    "            \n",
    "        revised = survey_dict.get('revised_survey', {})\n",
    "        print(\"=== Revised Survey ===\")\n",
    "        print(f\"Theme:   {revised['theme']}\")\n",
    "        print(f\"Purpose: {revised['purpose']}\\n\")\n",
    "        for q in revised['questions']:\n",
    "            print(f\"Q{q['question_id']}: {q['question_text']}\")\n",
    "            opts = q['input_config'].get('options')\n",
    "            if opts:\n",
    "                print(\"  Options:\")\n",
    "                for o in opts:\n",
    "                    print(f\"    - {o}\")\n",
    "            print()\n",
    "        self.state['survey_dict'] = survey_dict\n",
    "        return survey_dict\n",
    "\n",
    "        \n",
    "flow = SurveyFlow(\n",
    "    agents=[convert_agent, editor_agent],\n",
    "    tasks=[convert_task, research_task, improve_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "        \n",
    "import re\n",
    "\n",
    "def survey_dict_to_qualtrics_payload(survey_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    将自定义 survey_dict 转成 Qualtrics v3 API 的 survey-definitions payload\n",
    "    支持题型：multiple_choice, single_choice, slider, text_input\n",
    "    \"\"\"\n",
    "    survey_meta = survey_dict[\"revised_survey\"]\n",
    "    payload = {\n",
    "        \"SurveyName\":      survey_meta.get(\"theme\", \"New Survey\"),\n",
    "        \"Language\":        \"EN\",\n",
    "        \"ProjectCategory\": \"CORE\",\n",
    "        \"Questions\":       {}\n",
    "    }\n",
    "\n",
    "    for q in survey_meta[\"questions\"]:\n",
    "        raw_id = q[\"question_id\"]                  # e.g. \"q4\"\n",
    "        num    = re.sub(r'\\D+', '', raw_id)        # 提取数字 \"4\"\n",
    "        qid    = f\"QID{num}\"                       # 组装 \"QID4\"\n",
    "\n",
    "        qt  = q[\"question_text\"]\n",
    "        it  = q[\"input_type\"]\n",
    "        cfg = q[\"input_config\"]\n",
    "\n",
    "        # ---- 通用字段 ----\n",
    "        qobj = {\n",
    "            \"QuestionText\":      qt,\n",
    "            \"DataExportTag\":     qid,\n",
    "            \"Configuration\":     {\"QuestionDescriptionOption\": \"UseText\"},\n",
    "            \"Validation\":        {\"Settings\": {\"ForceResponse\": \"OFF\", \"Type\": \"None\"}}\n",
    "        }\n",
    "\n",
    "        # ---- 多／单选题 ----\n",
    "        if it in (\"multiple_choice\", \"single_choice\"):\n",
    "            choices = {}\n",
    "            for opt in cfg.get(\"options\", []):\n",
    "                if \"=\" in opt:\n",
    "                    idx, txt = opt.split(\"=\", 1)\n",
    "                    idx, txt = idx.strip(), txt.strip()\n",
    "                else:\n",
    "                    idx = str(len(choices) + 1)\n",
    "                    txt = opt.strip()\n",
    "                choices[idx] = {\"Display\": txt}\n",
    "\n",
    "            qobj.update({\n",
    "                \"QuestionType\": \"MC\",\n",
    "                \"Selector\":     \"SAVR\" if it == \"multiple_choice\" else \"SINGLE\",\n",
    "                \"SubSelector\":  \"TX\",\n",
    "                \"Choices\":      choices\n",
    "            })\n",
    "\n",
    "        # ---- 滑块题 ----\n",
    "        elif it == \"slider\":\n",
    "            # 从 cfg 安全读取滑块参数（默认 0–100，步长 1）\n",
    "            start = cfg.get(\"min\", cfg.get(\"start\", 0))\n",
    "            end   = cfg.get(\"max\", cfg.get(\"end\", 100))\n",
    "            step  = cfg.get(\"step\", cfg.get(\"stepSize\", 1))\n",
    "        \n",
    "            # 把所有滑块设置放在 qobj 根部\n",
    "            \n",
    "            qobj.update({\n",
    "                \"QuestionType\": \"SL\",\n",
    "                \"Selector\":     \"Slider\",\n",
    "                \"SubSelector\":  \"SL\",\n",
    "                \"SliderStart\":  start,\n",
    "                \"SliderEnd\":    end,\n",
    "                \"SliderStep\":   step\n",
    "            })\n",
    "        elif it == \"text_input\":   \n",
    "            qobj.update({\n",
    "                \"QuestionType\": \"TE\",\n",
    "                \"Selector\":     \"ML\"   # Text Entry 必须用 ML\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input_type: {it!r}\")\n",
    "\n",
    "        # 插入最终 payload\n",
    "        payload[\"Questions\"][qid] = qobj\n",
    "\n",
    "    return payload\n",
    "\n",
    "\n",
    "# def survey_dict_to_qualtrics_payload(survey_dict: dict) -> dict:\n",
    "#     \"\"\"\n",
    "#     input survey_dict\n",
    "#       - theme(for SurveyName)\n",
    "#       - purpose (Description)\n",
    "#       - questions: List of { question_id, question_text, input_type, input_config }\n",
    "#     Qualtrics v3 API 的 survey-definitions JSON\n",
    "#     \"\"\"\n",
    "\n",
    "#     survey_meta = survey_dict[\"revised_survey\"] \n",
    "#     payload = {\n",
    "#         \"SurveyName\": survey_meta.get(\"theme\", \"New Survey\"),\n",
    "#         \"Language\": \"EN\",\n",
    "#         \"ProjectCategory\": \"CORE\",\n",
    "#         \"Questions\": {}\n",
    "#     }\n",
    "#     questions = survey_meta[\"questions\"]\n",
    "#     for q in questions:\n",
    "#         qid = q[\"question_id\"]\n",
    "#         qt = q[\"question_text\"]\n",
    "#         it = q[\"input_type\"]\n",
    "#         cfg = q[\"input_config\"]\n",
    "\n",
    "#         qobj = {\n",
    "#             \"QuestionText\": qt,\n",
    "#             \"Configuration\": {\"QuestionDescriptionOption\": \"UseText\"},\n",
    "#             \"Validation\": {\"Settings\": {\"ForceResponse\": \"OFF\", \"Type\": \"None\"}}\n",
    "#         }\n",
    "\n",
    "#         if it in (\"multiple_choice\", \"single_choice\"):\n",
    "#             choices_dict = {}\n",
    "#             for opt in cfg[\"options\"]:\n",
    "#                 if \"=\" in opt:\n",
    "#                     index, text = opt.split(\"=\", 1)\n",
    "#                     choices_dict[index.strip()] = {\"Display\": text.strip()}\n",
    "#                 else:\n",
    "#                     idx = str(len(choices_dict)+1)\n",
    "#                     choices_dict[idx] = {\"Display\": opt.strip()}\n",
    "            \n",
    "#             qobj.update({\n",
    "#                 \"QuestionType\": \"MC\",\n",
    "#                 \"Selector\": \"SAVR\" if it == \"multiple_choice\" else \"SINGLE\",\n",
    "#                 \"SubSelector\": \"TX\",\n",
    "#                 \"Choices\": choices_dict\n",
    "#             })\n",
    "\n",
    "#         elif it == \"slider\":\n",
    "#             qobj.update({\n",
    "#                 \"QuestionType\": \"SL\",\n",
    "#                 \"Selector\": \"Slider\",\n",
    "#                 \"SubSelector\": \"SL\"\n",
    "#             })\n",
    "         \n",
    "\n",
    "#         elif it == \"text_input\":\n",
    "#             qobj.update({\n",
    "#                 \"QuestionType\": \"TE\",\n",
    "#                 \"Selector\": \"ML\" if cfg.get(\"multiline\", False) else \"TX\"\n",
    "#             })\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported input_type: {it}\")\n",
    "        \n",
    "#         payload[\"Questions\"][qid] = qobj\n",
    "\n",
    "#     return payload\n",
    "\n",
    "class QualtricsClient:\n",
    "    \"\"\"Handles all Qualtrics API interactions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Qualtrics API client with credentials from .env file\"\"\"\n",
    "        # Print current working directory to help debug file path issues\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        \n",
    "        # Check if .env file exists\n",
    "        if os.path.exists('.env'):\n",
    "            print(\"Found .env file in current directory\")\n",
    "        else:\n",
    "            print(\"WARNING: No .env file found in current directory!\")\n",
    "            \n",
    "        # Load environment variables\n",
    "        load_dotenv(verbose=True)\n",
    "        \n",
    "        self.api_token = os.getenv('QUALTRICS_API_TOKEN')\n",
    "        self.data_center = os.getenv('QUALTRICS_DATA_CENTER')\n",
    "        self.directory_id = os.getenv('QUALTRICS_DIRECTORY_ID')\n",
    "        \n",
    "        # Print obfuscated token for debugging (only first/last 4 chars)\n",
    "        if self.api_token:\n",
    "            token_length = len(self.api_token)\n",
    "            masked_token = self.api_token[:4] + '*' * (token_length - 8) + self.api_token[-4:] if token_length > 8 else \"****\"\n",
    "            print(f\"API Token loaded (masked): {masked_token}\")\n",
    "        else:\n",
    "            print(\"WARNING: No API token found in environment variables!\")\n",
    "            \n",
    "        if self.data_center:\n",
    "            print(f\"Data center: {self.data_center}\")\n",
    "        else:\n",
    "            print(\"WARNING: No data center found in environment variables!\")\n",
    "        \n",
    "        if not self.api_token or not self.data_center:\n",
    "            raise ValueError(\"Missing Qualtrics API credentials in .env file\")\n",
    "            \n",
    "        # Set up base URL for API requests\n",
    "        self.base_url = f\"https://{self.data_center}.qualtrics.com/API/v3/\"\n",
    "        self.headers = {\n",
    "            \"X-API-Token\": self.api_token,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Test connection\n",
    "        print(\"Testing Qualtrics API connection...\")\n",
    "        try:\n",
    "            test_url = f\"{self.base_url}whoami\"\n",
    "            response = requests.get(test_url, headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                user_info = response.json()[\"result\"]\n",
    "                print(f\"Connection successful! Authenticated as: {user_info.get('firstName', '')} {user_info.get('lastName', '')}\")\n",
    "            else:\n",
    "                print(f\"Connection test failed with status code: {response.status_code}\")\n",
    "                print(f\"Response: {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error testing connection: {str(e)}\")\n",
    "        \n",
    "    def create_survey(self, survey_name, survey_template=None):\n",
    "        \"\"\"\n",
    "        Create a new survey in Qualtrics\n",
    "        \n",
    "        Args:\n",
    "            survey_name (str): Name of the survey\n",
    "            survey_template (dict, optional): Survey template JSON\n",
    "            \n",
    "        Returns:\n",
    "            str: Survey ID of the created survey\n",
    "        \"\"\"\n",
    "        print(f\"Creating survey: {survey_name}\")\n",
    "        \n",
    "        # If no template is provided, use a basic template\n",
    "        if not survey_template:\n",
    "            # Define the survey payload with required fields including ProjectCategory\n",
    "            survey_payload = {\n",
    "                \"SurveyName\": survey_name,\n",
    "                \"Language\": \"EN\",\n",
    "                \"ProjectCategory\": \"CORE\", # This is the required field that was missing\n",
    "                \"Questions\": {\n",
    "                    \"QID1\": {\n",
    "                        \"QuestionText\": \"What is your age?\",\n",
    "                        \"QuestionType\": \"MC\",\n",
    "                        \"Selector\": \"SAVR\", # Required selector for multiple choice questions\n",
    "                        \"SubSelector\": \"TX\", # Text selector\n",
    "                        \"Configuration\": {\n",
    "                            \"QuestionDescriptionOption\": \"UseText\"\n",
    "                        },\n",
    "                        \"Validation\": {\n",
    "                            \"Settings\": {\n",
    "                                \"ForceResponse\": \"OFF\",\n",
    "                                \"Type\": \"None\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"Choices\": {\n",
    "                            \"1\": {\"Display\": \"18-24\"},\n",
    "                            \"2\": {\"Display\": \"25-34\"},\n",
    "                            \"3\": {\"Display\": \"35-44\"},\n",
    "                            \"4\": {\"Display\": \"45-54\"},\n",
    "                            \"5\": {\"Display\": \"55-64\"},\n",
    "                            \"6\": {\"Display\": \"65+\"}\n",
    "                        }\n",
    "                    },\n",
    "                    \"QID2\": {\n",
    "                        \"QuestionText\": \"How satisfied are you with our product?\",\n",
    "                        \"QuestionType\": \"Likert\",\n",
    "                        \"Selector\": \"LSL\", # Likert scale\n",
    "                        \"SubSelector\": \"TX\", # Text selector\n",
    "                        \"Configuration\": {\n",
    "                            \"QuestionDescriptionOption\": \"UseText\"\n",
    "                        },\n",
    "                        \"Validation\": {\n",
    "                            \"Settings\": {\n",
    "                                \"ForceResponse\": \"OFF\",\n",
    "                                \"Type\": \"None\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"Choices\": {\n",
    "                            \"1\": {\"Display\": \"Very dissatisfied\"},\n",
    "                            \"2\": {\"Display\": \"Dissatisfied\"},\n",
    "                            \"3\": {\"Display\": \"Neutral\"},\n",
    "                            \"4\": {\"Display\": \"Satisfied\"},\n",
    "                            \"5\": {\"Display\": \"Very satisfied\"}\n",
    "                        }\n",
    "                    },\n",
    "                    \"QID3\": {\n",
    "                        \"QuestionText\": \"Any additional comments?\",\n",
    "                        \"QuestionType\": \"TE\", # Text entry\n",
    "                        \"Selector\": \"ML\", # Multi-line\n",
    "                        \"Configuration\": {\n",
    "                            \"QuestionDescriptionOption\": \"UseText\"\n",
    "                        },\n",
    "                        \"Validation\": {\n",
    "                            \"Settings\": {\n",
    "                                \"ForceResponse\": \"OFF\",\n",
    "                                \"Type\": \"None\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            # If a template is provided, make sure it includes ProjectCategory\n",
    "            survey_payload = survey_template\n",
    "            if \"ProjectCategory\" not in survey_payload:\n",
    "                survey_payload[\"ProjectCategory\"] = \"CORE\"\n",
    "        \n",
    "        # Create survey\n",
    "        url = f\"{self.base_url}survey-definitions\"\n",
    "        payload = json.dumps(survey_payload)\n",
    "        \n",
    "        print(f\"Sending payload to Qualtrics: {payload[:200]}...\")\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, data=payload)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error response: {response.text}\")\n",
    "            raise Exception(f\"Failed to create survey: {response.text}\")\n",
    "        \n",
    "        result = response.json()\n",
    "        survey_id = result[\"result\"][\"SurveyID\"]\n",
    "        print(f\"Survey created successfully with ID: {survey_id}\")\n",
    "        \n",
    "        return survey_id\n",
    "\n",
    "    def add_questions(self, survey_id: str, questions: List[dict]):\n",
    "        for q in questions:\n",
    "            # start with the fields every question needs\n",
    "            q_payload = {\n",
    "                 \"QuestionID\":   q[\"question_id\"],\n",
    "                 \"QuestionText\": q[\"question_text\"],\n",
    "                 \"QuestionType\": q[\"QuestionType\"],\n",
    "                 \"DataExportTag\": q[\"question_id\"],    # \n",
    "                 \"Configuration\": {\"QuestionDescriptionOption\": \"UseText\"},\n",
    "                 \"Validation\":    {\"Settings\": {\"ForceResponse\": \"OFF\", \"Type\": \"None\"}},\n",
    "             }\n",
    "\n",
    "            # q_payload = {\n",
    "            #     \"QuestionID\":   q[\"question_id\"],\n",
    "            #     \"QuestionText\": q[\"question_text\"],\n",
    "            #     \"QuestionType\": q[\"QuestionType\"],\n",
    "            #     \"Configuration\": {\"QuestionDescriptionOption\": \"UseText\"},\n",
    "            #     \"Validation\":    {\"Settings\": {\"ForceResponse\": \"OFF\", \"Type\": \"None\"}},\n",
    "            # }\n",
    "            # only add Selector/SubSelector if given\n",
    "            if \"Selector\" in q:\n",
    "                q_payload[\"Selector\"] = q[\"Selector\"]\n",
    "            if \"SubSelector\" in q:\n",
    "                q_payload[\"SubSelector\"] = q[\"SubSelector\"]\n",
    "            # only add Choices if given\n",
    "            if \"Choices\" in q:\n",
    "                q_payload[\"Choices\"] = q[\"Choices\"]\n",
    "    \n",
    "            url = f\"{self.base_url}survey-definitions/{survey_id}/questions\"\n",
    "            resp = requests.post(url, headers=self.headers, json=q_payload)\n",
    "            print(f\"POST questions → {resp.status_code}\", resp.json())\n",
    "\n",
    "\n",
    "    # def add_block(self, survey_id: str, block_id: str, question_ids: List[str]):\n",
    "    #     url = f\"{self.base_url}survey-definitions/{survey_id}/blocks\"\n",
    "    #     block_payload = {\n",
    "    #         \"BlockID\":       block_id,\n",
    "    #         \"Description\":   \"All Questions\",\n",
    "    #         \"Type\":          \"Standard\",\n",
    "    #         \"DataExportTag\": block_id,\n",
    "    #         \"BlockElements\": [\n",
    "    #             {\"Type\": \"Question\", \"QuestionID\": qid}\n",
    "    #             for qid in question_ids\n",
    "    #         ]\n",
    "    #     }\n",
    "    #     resp = requests.post(url, headers=self.headers, json=block_payload)\n",
    "    #     print(f\"POST blocks → {resp.status_code}\", resp.json())\n",
    "\n",
    "\n",
    "    def add_block(self, survey_id: str, block_payload: dict):\n",
    "        url = f\"{self.base_url}survey-definitions/{survey_id}/blocks\"\n",
    "        resp = requests.post(url, headers=self.headers, json=block_payload)\n",
    "        print(f\"POST blocks → {resp.status_code}\", resp.json())\n",
    "\n",
    "\n",
    "\n",
    "    def update_flow(self, survey_id: str, flow_payload: dict):\n",
    "        url = f\"{self.base_url}survey-definitions/{survey_id}/flow\"\n",
    "        resp = requests.put(url, headers=self.headers, json=flow_payload)\n",
    "        print(\"PUT flow →\", resp.status_code, resp.json())\n",
    "    \n",
    "    def activate_survey(self, survey_id):\n",
    "        \"\"\"\n",
    "        Activate a survey to make it available for distribution\n",
    "        \n",
    "        Args:\n",
    "            survey_id (str): ID of the survey to activate\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful\n",
    "        \"\"\"\n",
    "        print(f\"Activating survey: {survey_id}\")\n",
    "        \n",
    "        url = f\"{self.base_url}surveys/{survey_id}\"\n",
    "        payload = json.dumps({\"isActive\": True})\n",
    "        \n",
    "        response = requests.put(url, headers=self.headers, data=payload)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to activate survey: {response.text}\")\n",
    "        \n",
    "        print(f\"Survey activated successfully\")\n",
    "        return True\n",
    "    \n",
    "    def create_distribution_link(self, survey_id, link_type=\"Anonymous\"):\n",
    "        \"\"\"\n",
    "        Create a distribution link for a survey\n",
    "        \n",
    "        Args:\n",
    "            survey_id (str): ID of the survey to distribute\n",
    "            link_type (str): Type of link (Anonymous or Individual)\n",
    "            \n",
    "        Returns:\n",
    "            str: Distribution link URL\n",
    "        \"\"\"\n",
    "        print(f\"Creating distribution link for survey: {survey_id}\")\n",
    "        \n",
    "        # For anonymous links, we can construct the URL directly based on the standard pattern\n",
    "        # https://DATACENTERID.qualtrics.com/jfe/form/SURVEYID\n",
    "        if link_type == \"Anonymous\":\n",
    "            survey_link = f\"https://{self.data_center}.qualtrics.com/jfe/form/{survey_id}\"\n",
    "            print(f\"Anonymous survey link created: {survey_link}\")\n",
    "            return survey_link\n",
    "        \n",
    "        # For other distribution types, we would use the API, but that's not implemented yet\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Distribution type '{link_type}' is not yet supported\")\n",
    "    \n",
    "    def get_survey_responses(self, survey_id, file_format=\"csv\"):\n",
    "        \"\"\"\n",
    "        Download survey responses\n",
    "        \n",
    "        Args:\n",
    "            survey_id (str): ID of the survey\n",
    "            file_format (str): Format of the response file (csv, json, spss, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Survey responses as a DataFrame\n",
    "        \"\"\"\n",
    "        print(f\"Downloading responses for survey: {survey_id}\")\n",
    "        \n",
    "        # Step 1: Create the export\n",
    "        export_url = f\"{self.base_url}surveys/{survey_id}/export-responses\"\n",
    "        export_payload = json.dumps({\n",
    "            \"format\": file_format,\n",
    "            \"useLabels\": True\n",
    "        })\n",
    "        \n",
    "        export_response = requests.post(export_url, headers=self.headers, data=export_payload)\n",
    "        \n",
    "        if export_response.status_code != 200:\n",
    "            raise Exception(f\"Failed to initiate export: {export_response.text}\")\n",
    "        \n",
    "        progress_id = export_response.json()[\"result\"][\"progressId\"]\n",
    "        \n",
    "        # Step 2: Check export progress\n",
    "        progress_status = \"inProgress\"\n",
    "        progress = 0\n",
    "        \n",
    "        while progress_status != \"complete\" and progress < 100:\n",
    "            progress_url = f\"{self.base_url}surveys/{survey_id}/export-responses/{progress_id}\"\n",
    "            progress_response = requests.get(progress_url, headers=self.headers)\n",
    "            \n",
    "            if progress_response.status_code != 200:\n",
    "                raise Exception(f\"Failed to check export progress: {progress_response.text}\")\n",
    "            \n",
    "            progress_result = progress_response.json()[\"result\"]\n",
    "            progress_status = progress_result[\"status\"]\n",
    "            progress = progress_result.get(\"percentComplete\", 0)\n",
    "            \n",
    "            print(f\"Export progress: {progress}%\")\n",
    "            \n",
    "            if progress_status != \"complete\" and progress < 100:\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # Step 3: Download the file\n",
    "        file_id = progress_result[\"fileId\"]\n",
    "        download_url = f\"{self.base_url}surveys/{survey_id}/export-responses/{file_id}/file\"\n",
    "        download_response = requests.get(download_url, headers=self.headers)\n",
    "        \n",
    "        if download_response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download responses: {download_response.text}\")\n",
    "        \n",
    "        # Step 4: Extract and parse the zip file\n",
    "        with zipfile.ZipFile(io.BytesIO(download_response.content)) as zip_file:\n",
    "            data_file = [f for f in zip_file.namelist() if f.endswith(f\".{file_format}\")][0]\n",
    "            with zip_file.open(data_file) as file:\n",
    "                if file_format == \"csv\":\n",
    "                    df = pd.read_csv(file)\n",
    "                elif file_format == \"json\":\n",
    "                    df = pd.read_json(file)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "        \n",
    "        print(f\"Successfully downloaded {len(df)} responses\")\n",
    "        return df\n",
    "    ...\n",
    "\n",
    "class MTurkClient:\n",
    "    \"\"\"Handles all MTurk API interactions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        aws_access_key_id: str = None,\n",
    "        aws_secret_access_key: str = None,\n",
    "        use_sandbox: bool = True\n",
    "        ):\n",
    "\n",
    "        if aws_access_key_id and aws_secret_access_key:\n",
    "            self.aws_access_key_id     = aws_access_key_id\n",
    "            self.aws_secret_access_key = aws_secret_access_key\n",
    "        else:\n",
    "            self.aws_access_key_id     = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "            self.aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "        self.use_sandbox = use_sandbox\n",
    "\n",
    "        if not self.aws_access_key_id or not self.aws_secret_access_key:\n",
    "            raise ValueError(\"Missing AWS credentials\")\n",
    "\n",
    "        region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "        endpoint = (\n",
    "            'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "            if self.use_sandbox else\n",
    "            'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "        )\n",
    "\n",
    "        self.client = boto3.client(\n",
    "            'mturk',\n",
    "            aws_access_key_id=self.aws_access_key_id,\n",
    "            aws_secret_access_key=self.aws_secret_access_key,\n",
    "            region_name=region,\n",
    "            endpoint_url=endpoint\n",
    "        )\n",
    "        print(f\"MTurk client initialized in {'Sandbox' if self.use_sandbox else 'Production'} mode\")\n",
    "        \n",
    "    def get_account_balance(self):\n",
    "        \"\"\"Get the available MTurk account balance\"\"\"\n",
    "        response = self.client.get_account_balance()\n",
    "        balance = response['AvailableBalance']\n",
    "        print(f\"MTurk account balance: ${balance}\")\n",
    "        return float(balance)\n",
    "    \n",
    "    def create_hit_with_survey_link(self, survey_link, hit_config=None):\n",
    "        \"\"\"\n",
    "        Create an MTurk HIT with a link to a Qualtrics survey\n",
    "        \n",
    "        Args:\n",
    "            survey_link (str): URL to the Qualtrics survey\n",
    "            hit_config (dict, optional): Custom configuration for the HIT\n",
    "            \n",
    "        Returns:\n",
    "            str: HIT ID\n",
    "        \"\"\"\n",
    "        print(\"Creating MTurk HIT with survey link\")\n",
    "        \n",
    "        # Default HIT configuration\n",
    "        if not hit_config:\n",
    "            hit_config = {\n",
    "                'Title': 'Complete a short survey',\n",
    "                'Description': 'We need your input for a quick survey that should take less than 10 minutes',\n",
    "                'Keywords': 'survey, research, opinion, feedback',\n",
    "                'Reward': '0.50',\n",
    "                'MaxAssignments': 100,\n",
    "                'LifetimeInSeconds': 86400,  # 1 day\n",
    "                'AssignmentDurationInSeconds': 1800,  # 30 minutes\n",
    "                'AutoApprovalDelayInSeconds': 86400,  # 1 day\n",
    "                'QualificationRequirements': []\n",
    "            }\n",
    "        \n",
    "        # Create the HTML question with the survey link\n",
    "        question_html = f\"\"\"\n",
    "        <HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\">\n",
    "            <HTMLContent><![CDATA[\n",
    "                <!DOCTYPE html>\n",
    "                <html>\n",
    "                <head>\n",
    "                    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n",
    "                    <script type='text/javascript' src='https://s3.amazonaws.com/mturk-public/externalHIT_v1.js'></script>\n",
    "                </head>\n",
    "                <body>\n",
    "                    <form name='mturk_form' method='post' id='mturk_form' action='https://www.mturk.com/mturk/externalSubmit'>\n",
    "                        <input type='hidden' value='' name='assignmentId' id='assignmentId'/>\n",
    "                        <h1>Survey Task</h1>\n",
    "                        <p>Please complete the survey at the following link:</p>\n",
    "                        <p><a href='{survey_link}' target='_blank'>{survey_link}</a></p>\n",
    "                        <p>After completing the survey, you will receive a completion code. Enter the code below:</p>\n",
    "                        <p><input type='text' name='completion_code' id='completion_code' size='40'/></p>\n",
    "                        <p><input type='submit' id='submitButton' value='Submit' /></p>\n",
    "                    </form>\n",
    "                    <script language='Javascript'>\n",
    "                        turkSetAssignmentID();\n",
    "                    </script>\n",
    "                </body>\n",
    "                </html>\n",
    "            ]]></HTMLContent>\n",
    "            <FrameHeight>600</FrameHeight>\n",
    "        </HTMLQuestion>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create the HIT\n",
    "        response = self.client.create_hit(\n",
    "            Title=hit_config['Title'],\n",
    "            Description=hit_config['Description'],\n",
    "            Keywords=hit_config['Keywords'],\n",
    "            Reward=hit_config['Reward'],\n",
    "            MaxAssignments=hit_config['MaxAssignments'],\n",
    "            LifetimeInSeconds=hit_config['LifetimeInSeconds'],\n",
    "            AssignmentDurationInSeconds=hit_config['AssignmentDurationInSeconds'],\n",
    "            AutoApprovalDelayInSeconds=hit_config['AutoApprovalDelayInSeconds'],\n",
    "            Question=question_html,\n",
    "            QualificationRequirements=hit_config['QualificationRequirements']\n",
    "        )\n",
    "        \n",
    "        hit_id = response['HIT']['HITId']\n",
    "        hit_type_id = response['HIT']['HITTypeId']\n",
    "        \n",
    "        print(f\"HIT created successfully with ID: {hit_id}\")\n",
    "        \n",
    "        # Print the HIT URL\n",
    "        if self.use_sandbox:\n",
    "            worker_url = f\"https://workersandbox.mturk.com/mturk/preview?groupId={hit_type_id}\"\n",
    "        else:\n",
    "            worker_url = f\"https://worker.mturk.com/mturk/preview?groupId={hit_type_id}\"\n",
    "            \n",
    "        print(f\"Workers can access the HIT at: {worker_url}\")\n",
    "        \n",
    "        return hit_id\n",
    "    \n",
    "    def get_hit_assignments(self, hit_id):\n",
    "        \"\"\"\n",
    "        Get all assignments for a HIT\n",
    "        \n",
    "        Args:\n",
    "            hit_id (str): ID of the HIT\n",
    "            \n",
    "        Returns:\n",
    "            list: List of assignment dictionaries\n",
    "        \"\"\"\n",
    "        print(f\"Getting assignments for HIT: {hit_id}\")\n",
    "        \n",
    "        # List to store all assignments\n",
    "        all_assignments = []\n",
    "        \n",
    "        # Get assignments with pagination\n",
    "        next_token = None\n",
    "        \n",
    "        while True:\n",
    "            if next_token:\n",
    "                response = self.client.list_assignments_for_hit(\n",
    "                    HITId=hit_id,\n",
    "                    NextToken=next_token,\n",
    "                    MaxResults=100\n",
    "                )\n",
    "            else:\n",
    "                response = self.client.list_assignments_for_hit(\n",
    "                    HITId=hit_id,\n",
    "                    MaxResults=100\n",
    "                )\n",
    "            \n",
    "            all_assignments.extend(response['Assignments'])\n",
    "            \n",
    "            if 'NextToken' in response:\n",
    "                next_token = response['NextToken']\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(f\"Found {len(all_assignments)} assignments\")\n",
    "        return all_assignments\n",
    "    \n",
    "    def approve_assignments(self, assignments, feedback=None):\n",
    "        \"\"\"\n",
    "        Approve multiple assignments\n",
    "        \n",
    "        Args:\n",
    "            assignments (list): List of assignment dictionaries or IDs\n",
    "            feedback (str, optional): Feedback to workers\n",
    "            \n",
    "        Returns:\n",
    "            int: Number of successfully approved assignments\n",
    "        \"\"\"\n",
    "        approved_count = 0\n",
    "        \n",
    "        for assignment in assignments:\n",
    "            # Extract assignment ID if a dictionary was provided\n",
    "            assignment_id = assignment['AssignmentId'] if isinstance(assignment, dict) else assignment\n",
    "            \n",
    "            try:\n",
    "                self.client.approve_assignment(\n",
    "                    AssignmentId=assignment_id,\n",
    "                    RequesterFeedback=feedback if feedback else \"Thank you for your participation!\"\n",
    "                )\n",
    "                approved_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error approving assignment {assignment_id}: {str(e)}\")\n",
    "        \n",
    "        print(f\"Successfully approved {approved_count} assignments\")\n",
    "        return approved_count\n",
    "    \n",
    "    def delete_hit(self, hit_id):\n",
    "        \"\"\"\n",
    "        Delete a HIT\n",
    "        \n",
    "        Args:\n",
    "            hit_id (str): ID of the HIT to delete\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get the HIT status\n",
    "            hit = self.client.get_hit(HITId=hit_id)\n",
    "            status = hit['HIT']['HITStatus']\n",
    "            \n",
    "            # If the HIT is reviewable, dispose of it\n",
    "            if status == 'Reviewable':\n",
    "                self.client.delete_hit(HITId=hit_id)\n",
    "                print(f\"HIT {hit_id} deleted successfully\")\n",
    "                return True\n",
    "            \n",
    "            # If the HIT is assignable, expire it first then delete it\n",
    "            elif status == 'Assignable':\n",
    "                self.client.update_expiration_for_hit(\n",
    "                    HITId=hit_id,\n",
    "                    ExpireAt=datetime(2015, 1, 1)  # Set to a past date to expire immediately\n",
    "                )\n",
    "                time.sleep(1)  # Give time for the HIT to update\n",
    "                self.client.delete_hit(HITId=hit_id)\n",
    "                print(f\"HIT {hit_id} expired and deleted successfully\")\n",
    "                return True\n",
    "                \n",
    "            else:\n",
    "                print(f\"Cannot delete HIT {hit_id}, status is {status}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting HIT {hit_id}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "\n",
    "class QualtricsAndMTurkAutomation:\n",
    "    def __init__(self, mturk_client: Optional[MTurkClient] = None):\n",
    "        load_dotenv()\n",
    "        self.qualtrics = QualtricsClient()\n",
    "        self.mturk     = mturk_client or MTurkClient()\n",
    "\n",
    "    def run(self, survey_payload: dict, hit_config: dict) -> dict:\n",
    "        survey_id = self.qualtrics.create_survey(\n",
    "            survey_name=survey_payload[\"SurveyName\"],\n",
    "            survey_template=survey_payload\n",
    "        )\n",
    "\n",
    "        questions = []\n",
    "        for qid, qobj in survey_payload[\"Questions\"].items():\n",
    "            num = qid.lstrip(\"Q\")\n",
    "            real_qid = f\"QID{num}\"\n",
    "            \n",
    "            q_data = {\n",
    "                \"question_id\":   real_qid,\n",
    "                \"question_text\": qobj[\"QuestionText\"],\n",
    "                \"QuestionID\":    real_qid,\n",
    "                \"QuestionText\":  qobj[\"QuestionText\"],\n",
    "                \"QuestionType\":  qobj[\"QuestionType\"],\n",
    "                \"Selector\":      qobj[\"Selector\"]\n",
    "            }\n",
    "            \n",
    "            if \"SubSelector\" in qobj:\n",
    "                q_data[\"SubSelector\"] = qobj[\"SubSelector\"]\n",
    "            \n",
    "            if \"Choices\" in qobj:\n",
    "                q_data[\"Choices\"] = qobj[\"Choices\"]\n",
    "            \n",
    "            questions.append(q_data)\n",
    "\n",
    "\n",
    "        # questions = []\n",
    "        # for qid, qobj in survey_payload[\"Questions\"].items():\n",
    "        #     num = qid.lstrip(\"Q\")\n",
    "        #     real_qid = f\"QID{num}\"\n",
    "        #     questions.append({\n",
    "        #         \"question_id\":   real_qid,           \n",
    "        #         \"question_text\": qobj[\"QuestionText\"], \n",
    "        #         \"QuestionID\":    real_qid,          \n",
    "        #         \"QuestionText\":  qobj[\"QuestionText\"],\n",
    "        #         \"QuestionType\":  qobj[\"QuestionType\"],\n",
    "        #         \"Selector\":      qobj[\"Selector\"],\n",
    "        #         \"SubSelector\":   qobj[\"SubSelector\"],\n",
    "        #         \"Choices\":       qobj[\"Choices\"]\n",
    "        #     })\n",
    "        self.qualtrics.add_questions(survey_id, questions)\n",
    "\n",
    "\n",
    "        comp_qid = f\"QID{len(questions)+1}\"\n",
    "        self.qualtrics.add_questions(survey_id, [{\n",
    "            \"question_id\":   comp_qid,\n",
    "            \"question_text\": (\n",
    "                \"Thank you for completing the survey!\\n\"\n",
    "                \"Your completion code is: ${e://Field/ResponseID}\"\n",
    "            ),\n",
    "            \"QuestionID\":    comp_qid,\n",
    "            \"QuestionText\":  (\n",
    "                \"Thank you for completing the survey!\\n\"\n",
    "                \"Your completion code is: ${e://Field/ResponseID}\"\n",
    "            ),\n",
    "            \"QuestionType\":  \"DB\",   # Descriptive Text\n",
    "            \"Selector\":      \"TB\"    # Text/Graphic Block\n",
    "        }])\n",
    "\n",
    "        self.qualtrics.activate_survey(survey_id)\n",
    "\n",
    "        survey_link = self.qualtrics.create_distribution_link(survey_id)\n",
    "\n",
    "        hit_id = self.mturk.create_hit_with_survey_link(survey_link, hit_config)\n",
    "\n",
    "        return {\n",
    "            \"survey_id\":   survey_id,\n",
    "            \"survey_link\": survey_link,\n",
    "            \"hit_id\":      hit_id\n",
    "        }\n",
    "    def collect_and_process_results(self, survey_id, hit_id, auto_approve=True):\n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "         \n",
    "            responses_df = self.qualtrics.get_survey_responses(survey_id)\n",
    "            results['responses'] = responses_df\n",
    "            \n",
    "\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            csv_filename = f\"survey_responses_{timestamp}.csv\"\n",
    "            responses_df.to_csv(csv_filename, index=False)\n",
    "            results['csv_filename'] = csv_filename\n",
    "            \n",
    "            print(f\"Saved {len(responses_df)} responses to {csv_filename}\")\n",
    "            \n",
    "            assignments = self.mturk.get_hit_assignments(hit_id)\n",
    "            results['assignments'] = assignments\n",
    "            \n",
    "            if auto_approve and assignments:\n",
    "                approved_count = self.mturk.approve_assignments(assignments)\n",
    "                results['approved_count'] = approved_count\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting results: {str(e)}\")\n",
    "            return results\n",
    "\n",
    "\n",
    "\n",
    "import asyncio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # survey_to_process = \"\"\"\n",
    "    # Topic: The Theory of Planned Behavior Survey\n",
    "    # Questions:\n",
    "    # 1. I intend to purchase organic food in the next month. (1=Strongly disagree; 7=Strongly agree)\n",
    "    # 2. Buying organic food is beneficial to my health. (1=Strongly disagree; 7=Strongly agree)\n",
    "    # 3. I feel confident in my ability to purchase organic food if I want to. (1=Strongly disagree; 7=Strongly agree)\n",
    "    # 4. How do I think of the organic food (text question)\n",
    "    # 5. The decision to buy organic food is entirely up to me. (1=Strongly disagree; 7=Strongly agree)\n",
    "    # 6. What barriers, if any, prevent you from buying organic food? (text question)\n",
    "    # 7. How do elders think of organic food? (text question)\n",
    "    # \"\"\"\n",
    "    print(\"========================================\")\n",
    "    print(\"⚠️  INPUT REQUIREMENTS:\")\n",
    "    print(\"- You must include a line starting with 'Topic:'\")\n",
    "    print(\"- You must include at least one line starting with 'Questions:'\")\n",
    "    print(\"Otherwise, the survey cannot be processed.\")\n",
    "    print(\"========================================\")\n",
    "    survey_to_process = input(\"Please enter the Survey content: \")\n",
    "\n",
    "    survey_dict = await flow.kickoff_async(inputs={\n",
    "        'survey_text': survey_to_process\n",
    "    })\n",
    "\n",
    "    annotated = survey_dict['original_with_comments']\n",
    "    revised   = survey_dict['revised_survey'] \n",
    "\n",
    "    survey_dict = await flow.kickoff_async(inputs={\n",
    "        'survey_text': survey_to_process\n",
    "    })\n",
    "\n",
    "    \n",
    "    qualtrics_payload = survey_dict_to_qualtrics_payload(survey_dict)\n",
    "\n",
    "    aws_key    = \n",
    "    aws_secret = \n",
    "    mturk = MTurkClient(aws_key, aws_secret, use_sandbox=True)\n",
    "\n",
    "    hit_config = {\n",
    "        'Title': 'Complete a short survey on organic food',\n",
    "        'Description': survey_dict[\"revised_survey\"][\"purpose\"],\n",
    "        'Keywords': 'survey, research, feedback',\n",
    "        'Reward': '0.75',\n",
    "        'MaxAssignments': 100,\n",
    "        'LifetimeInSeconds': 86400,\n",
    "        'AssignmentDurationInSeconds': 1800,\n",
    "        'AutoApprovalDelayInSeconds': 86400,\n",
    "        'QualificationRequirements': []\n",
    "    }\n",
    "    \n",
    "    automation = QualtricsAndMTurkAutomation()\n",
    "    results = automation.run(qualtrics_payload, hit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf2a56-1cd1-415c-85e6-6a7756ee7255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Original Survey (with comments) ===\n",
      "Theme:   The Theory of Planned Behavior Survey\n",
      "Purpose: To assess consumer intentions and perceptions regarding organic food purchasing.\n",
      "\n",
      "Qq1: I intend to purchase organic food in the next month.\n",
      "  → Comment: Measures behavioral intentions effectively.\n",
      "\n",
      "Qq2: Buying organic food is beneficial to my health.\n",
      "  → Comment: Assesses important health beliefs regarding organic food.\n",
      "\n",
      "Qq3: I feel confident in my ability to purchase organic food if I want to.\n",
      "  → Comment: Focuses on self-efficacy, aligning with TPB.\n",
      "\n",
      "Qq4: How do I think of the organic food?\n",
      "  → Comment: Allows for qualitative insights into personal beliefs.\n",
      "\n",
      "Qq5: The decision to buy organic food is entirely up to me.\n",
      "  → Comment: Reiterates consumer autonomy in purchasing decisions.\n",
      "\n",
      "Qq6: What barriers, if any, prevent you from buying organic food?\n",
      "  → Comment: Identifies barriers that may inhibit organic food purchases.\n",
      "\n",
      "Qq7: How do elders think of organic food?\n",
      "  → Comment: Explores generational perspectives on organic food.\n",
      "\n",
      "Overall comment: The survey prompts are generally well-structured, but would benefit from greater clarity and specificity.\n",
      "\n",
      "=== Revised Survey ===\n",
      "Theme:   The Theory of Planned Behavior Survey\n",
      "Purpose: To assess consumer intentions and perceptions regarding organic food purchasing.\n",
      "\n",
      "Qq1: I plan to buy organic food within the next month.\n",
      "  Options:\n",
      "    - 1=Strongly disagree\n",
      "    - 2\n",
      "    - 3\n",
      "    - 4\n",
      "    - 5\n",
      "    - 6\n",
      "    - 7=Strongly agree\n",
      "\n",
      "Qq2: I believe that purchasing organic food contributes positively to my health.\n",
      "  Options:\n",
      "    - 1=Strongly disagree\n",
      "    - 2\n",
      "    - 3\n",
      "    - 4\n",
      "    - 5\n",
      "    - 6\n",
      "    - 7=Strongly agree\n",
      "\n",
      "Qq3: I am confident in my ability to purchase organic food when I choose to.\n",
      "  Options:\n",
      "    - 1=Strongly disagree\n",
      "    - 2\n",
      "    - 3\n",
      "    - 4\n",
      "    - 5\n",
      "    - 6\n",
      "    - 7=Strongly agree\n",
      "\n",
      "Qq4: In your own words, what are your thoughts on organic food?\n",
      "\n",
      "Qq5: I consider the decision to purchase organic food to be completely my own.\n",
      "  Options:\n",
      "    - 1=Strongly disagree\n",
      "    - 2\n",
      "    - 3\n",
      "    - 4\n",
      "    - 5\n",
      "    - 6\n",
      "    - 7=Strongly agree\n",
      "\n",
      "Qq6: What factors, if any, limit your ability to purchase organic food?\n",
      "\n",
      "Qq7: What do you think are the perceptions of elders regarding organic food?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Original Survey (with comments) ===\")\n",
    "print(f\"Theme:   {annotated['survey']['theme']}\")\n",
    "print(f\"Purpose: {annotated['survey']['purpose']}\\n\")\n",
    "for q in annotated['survey']['questions']:\n",
    "    print(f\"Q{q['question_id']}: {q['question_text']}\")\n",
    "    comment = next((c['comment'] \n",
    "                    for c in annotated['question_comments'] \n",
    "                    if c['question_id']==q['question_id']), None)\n",
    "    if comment:\n",
    "        print(f\"  → Comment: {comment}\")\n",
    "    print()\n",
    "if annotated.get('overall_comment'):\n",
    "    print(f\"Overall comment: {annotated['overall_comment']}\\n\")\n",
    "\n",
    "print(\"=== Revised Survey ===\")\n",
    "print(f\"Theme:   {revised['theme']}\")\n",
    "print(f\"Purpose: {revised['purpose']}\\n\")\n",
    "for q in revised['questions']:\n",
    "    print(f\"Q{q['question_id']}: {q['question_text']}\")\n",
    "    opts = q['input_config'].get('options')\n",
    "    if opts:\n",
    "        print(\"  Options:\")\n",
    "        for o in opts:\n",
    "            print(f\"    - {o}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec6c2d-fa2d-4a40-ab0c-ec73137a10b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to collect data for Survey ID: SV_5hXqPl4yhqXzBhY and HIT ID: 3LAZVA75O8O8VDMMCS3XOZDHD98O24\n",
      "Downloading responses for survey: SV_5hXqPl4yhqXzBhY\n",
      "Export progress: 0.0%\n",
      "Export progress: 0.0%\n",
      "Export progress: 100.0%\n",
      "Successfully downloaded 3 responses\n",
      "Saved 3 responses to survey_responses_20250507_104325.csv\n",
      "Getting assignments for HIT: 3LAZVA75O8O8VDMMCS3XOZDHD98O24\n",
      "Found 1 assignments\n",
      "Successfully approved 1 assignments\n",
      "Data collection completed. Summary:\n",
      "{'responses':                                  StartDate  \\\n",
      "0                               Start Date   \n",
      "1  {\"ImportId\":\"startDate\",\"timeZone\":\"Z\"}   \n",
      "2                      2025-05-07 14:42:05   \n",
      "\n",
      "                                 EndDate                 Status  \\\n",
      "0                               End Date          Response Type   \n",
      "1  {\"ImportId\":\"endDate\",\"timeZone\":\"Z\"}  {\"ImportId\":\"status\"}   \n",
      "2                    2025-05-07 14:42:18             IP Address   \n",
      "\n",
      "                  IPAddress                 Progress    Duration (in seconds)  \\\n",
      "0                IP Address                 Progress    Duration (in seconds)   \n",
      "1  {\"ImportId\":\"ipAddress\"}  {\"ImportId\":\"progress\"}  {\"ImportId\":\"duration\"}   \n",
      "2            216.165.95.164                      100                       12   \n",
      "\n",
      "                  Finished                                RecordedDate  \\\n",
      "0                 Finished                               Recorded Date   \n",
      "1  {\"ImportId\":\"finished\"}  {\"ImportId\":\"recordedDate\",\"timeZone\":\"Z\"}   \n",
      "2                     True                         2025-05-07 14:42:19   \n",
      "\n",
      "                 ResponseId                 RecipientLastName  ...  \\\n",
      "0               Response ID               Recipient Last Name  ...   \n",
      "1  {\"ImportId\":\"_recordId\"}  {\"ImportId\":\"recipientLastName\"}  ...   \n",
      "2         R_1NRsFphj2wLOdkq                               NaN  ...   \n",
      "\n",
      "                  LocationLongitude                 DistributionChannel  \\\n",
      "0                Location Longitude                Distribution Channel   \n",
      "1  {\"ImportId\":\"locationLongitude\"}  {\"ImportId\":\"distributionChannel\"}   \n",
      "2                          -73.9904                           anonymous   \n",
      "\n",
      "                  UserLanguage  \\\n",
      "0                User Language   \n",
      "1  {\"ImportId\":\"userLanguage\"}   \n",
      "2                           EN   \n",
      "\n",
      "                                              QIDID1  \\\n",
      "0  To what extent do you plan to purchase organic...   \n",
      "1                                {\"ImportId\":\"QID1\"}   \n",
      "2                                                  3   \n",
      "\n",
      "                                              QIDID2  \\\n",
      "0  In your opinion, how beneficial is buying orga...   \n",
      "1                                {\"ImportId\":\"QID2\"}   \n",
      "2                                                  3   \n",
      "\n",
      "                                              QIDID3  \\\n",
      "0  How confident are you in your ability to purch...   \n",
      "1                                {\"ImportId\":\"QID3\"}   \n",
      "2                                                  6   \n",
      "\n",
      "                                        QIDID4  \\\n",
      "0  Please share your thoughts on organic food.   \n",
      "1                     {\"ImportId\":\"QID4_TEXT\"}   \n",
      "2                                          NaN   \n",
      "\n",
      "                                              QIDID5  \\\n",
      "0  Do you feel that the decision to purchase orga...   \n",
      "1                                {\"ImportId\":\"QID5\"}   \n",
      "2                                                NaN   \n",
      "\n",
      "                                              QIDID6  \\\n",
      "0  What obstacles, if any, prevent you from buyin...   \n",
      "1                           {\"ImportId\":\"QID6_TEXT\"}   \n",
      "2                                                NaN   \n",
      "\n",
      "                                              QIDID7  \n",
      "0  What are the common perceptions among elders r...  \n",
      "1                           {\"ImportId\":\"QID7_TEXT\"}  \n",
      "2                                                NaN  \n",
      "\n",
      "[3 rows x 24 columns], 'csv_filename': 'survey_responses_20250507_104325.csv', 'assignments': [{'AssignmentId': '3X65QVEQJRKFAU8KMVHDXFEOCDCCLW', 'WorkerId': 'A2LQFMUQSJ6H2E', 'HITId': '3LAZVA75O8O8VDMMCS3XOZDHD98O24', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2025, 5, 8, 10, 42, 24, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2025, 5, 7, 10, 42, 2, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2025, 5, 7, 10, 42, 24, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>completion_code</QuestionIdentifier><FreeText>R_1NRsFphj2wLOdkq</FreeText></Answer></QuestionFormAnswers>'}], 'approved_count': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>LocationLongitude</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>QIDID1</th>\n",
       "      <th>QIDID2</th>\n",
       "      <th>QIDID3</th>\n",
       "      <th>QIDID4</th>\n",
       "      <th>QIDID5</th>\n",
       "      <th>QIDID6</th>\n",
       "      <th>QIDID7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start Date</td>\n",
       "      <td>End Date</td>\n",
       "      <td>Response Type</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>Progress</td>\n",
       "      <td>Duration (in seconds)</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Recorded Date</td>\n",
       "      <td>Response ID</td>\n",
       "      <td>Recipient Last Name</td>\n",
       "      <td>...</td>\n",
       "      <td>Location Longitude</td>\n",
       "      <td>Distribution Channel</td>\n",
       "      <td>User Language</td>\n",
       "      <td>To what extent do you plan to purchase organic...</td>\n",
       "      <td>In your opinion, how beneficial is buying orga...</td>\n",
       "      <td>How confident are you in your ability to purch...</td>\n",
       "      <td>Please share your thoughts on organic food.</td>\n",
       "      <td>Do you feel that the decision to purchase orga...</td>\n",
       "      <td>What obstacles, if any, prevent you from buyin...</td>\n",
       "      <td>What are the common perceptions among elders r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"ImportId\":\"startDate\",\"timeZone\":\"Z\"}</td>\n",
       "      <td>{\"ImportId\":\"endDate\",\"timeZone\":\"Z\"}</td>\n",
       "      <td>{\"ImportId\":\"status\"}</td>\n",
       "      <td>{\"ImportId\":\"ipAddress\"}</td>\n",
       "      <td>{\"ImportId\":\"progress\"}</td>\n",
       "      <td>{\"ImportId\":\"duration\"}</td>\n",
       "      <td>{\"ImportId\":\"finished\"}</td>\n",
       "      <td>{\"ImportId\":\"recordedDate\",\"timeZone\":\"Z\"}</td>\n",
       "      <td>{\"ImportId\":\"_recordId\"}</td>\n",
       "      <td>{\"ImportId\":\"recipientLastName\"}</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"ImportId\":\"locationLongitude\"}</td>\n",
       "      <td>{\"ImportId\":\"distributionChannel\"}</td>\n",
       "      <td>{\"ImportId\":\"userLanguage\"}</td>\n",
       "      <td>{\"ImportId\":\"QID1\"}</td>\n",
       "      <td>{\"ImportId\":\"QID2\"}</td>\n",
       "      <td>{\"ImportId\":\"QID3\"}</td>\n",
       "      <td>{\"ImportId\":\"QID4_TEXT\"}</td>\n",
       "      <td>{\"ImportId\":\"QID5\"}</td>\n",
       "      <td>{\"ImportId\":\"QID6_TEXT\"}</td>\n",
       "      <td>{\"ImportId\":\"QID7_TEXT\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-07 14:42:05</td>\n",
       "      <td>2025-05-07 14:42:18</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>216.165.95.164</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-07 14:42:19</td>\n",
       "      <td>R_1NRsFphj2wLOdkq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9904</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 StartDate  \\\n",
       "0                               Start Date   \n",
       "1  {\"ImportId\":\"startDate\",\"timeZone\":\"Z\"}   \n",
       "2                      2025-05-07 14:42:05   \n",
       "\n",
       "                                 EndDate                 Status  \\\n",
       "0                               End Date          Response Type   \n",
       "1  {\"ImportId\":\"endDate\",\"timeZone\":\"Z\"}  {\"ImportId\":\"status\"}   \n",
       "2                    2025-05-07 14:42:18             IP Address   \n",
       "\n",
       "                  IPAddress                 Progress    Duration (in seconds)  \\\n",
       "0                IP Address                 Progress    Duration (in seconds)   \n",
       "1  {\"ImportId\":\"ipAddress\"}  {\"ImportId\":\"progress\"}  {\"ImportId\":\"duration\"}   \n",
       "2            216.165.95.164                      100                       12   \n",
       "\n",
       "                  Finished                                RecordedDate  \\\n",
       "0                 Finished                               Recorded Date   \n",
       "1  {\"ImportId\":\"finished\"}  {\"ImportId\":\"recordedDate\",\"timeZone\":\"Z\"}   \n",
       "2                     True                         2025-05-07 14:42:19   \n",
       "\n",
       "                 ResponseId                 RecipientLastName  ...  \\\n",
       "0               Response ID               Recipient Last Name  ...   \n",
       "1  {\"ImportId\":\"_recordId\"}  {\"ImportId\":\"recipientLastName\"}  ...   \n",
       "2         R_1NRsFphj2wLOdkq                               NaN  ...   \n",
       "\n",
       "                  LocationLongitude                 DistributionChannel  \\\n",
       "0                Location Longitude                Distribution Channel   \n",
       "1  {\"ImportId\":\"locationLongitude\"}  {\"ImportId\":\"distributionChannel\"}   \n",
       "2                          -73.9904                           anonymous   \n",
       "\n",
       "                  UserLanguage  \\\n",
       "0                User Language   \n",
       "1  {\"ImportId\":\"userLanguage\"}   \n",
       "2                           EN   \n",
       "\n",
       "                                              QIDID1  \\\n",
       "0  To what extent do you plan to purchase organic...   \n",
       "1                                {\"ImportId\":\"QID1\"}   \n",
       "2                                                  3   \n",
       "\n",
       "                                              QIDID2  \\\n",
       "0  In your opinion, how beneficial is buying orga...   \n",
       "1                                {\"ImportId\":\"QID2\"}   \n",
       "2                                                  3   \n",
       "\n",
       "                                              QIDID3  \\\n",
       "0  How confident are you in your ability to purch...   \n",
       "1                                {\"ImportId\":\"QID3\"}   \n",
       "2                                                  6   \n",
       "\n",
       "                                        QIDID4  \\\n",
       "0  Please share your thoughts on organic food.   \n",
       "1                     {\"ImportId\":\"QID4_TEXT\"}   \n",
       "2                                          NaN   \n",
       "\n",
       "                                              QIDID5  \\\n",
       "0  Do you feel that the decision to purchase orga...   \n",
       "1                                {\"ImportId\":\"QID5\"}   \n",
       "2                                                NaN   \n",
       "\n",
       "                                              QIDID6  \\\n",
       "0  What obstacles, if any, prevent you from buyin...   \n",
       "1                           {\"ImportId\":\"QID6_TEXT\"}   \n",
       "2                                                NaN   \n",
       "\n",
       "                                              QIDID7  \n",
       "0  What are the common perceptions among elders r...  \n",
       "1                           {\"ImportId\":\"QID7_TEXT\"}  \n",
       "2                                                NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survey_id = results['survey_id']\n",
    "hit_id = results['hit_id']\n",
    "\n",
    "print(f\"Ready to collect data for Survey ID: {survey_id} and HIT ID: {hit_id}\")\n",
    "\n",
    "collected_data = automation.collect_and_process_results(\n",
    "    survey_id=survey_id,\n",
    "    hit_id=hit_id,\n",
    "    auto_approve=True \n",
    ")\n",
    "\n",
    "print(\"Data collection completed. Summary:\")\n",
    "print(collected_data)\n",
    "\n",
    "if 'responses' in collected_data:\n",
    "    display(collected_data['responses'])\n",
    "else:\n",
    "    print(\"No responses collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbdef5-a4e0-4956-b522-50756557de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b24d4c-66df-4898-87f2-87d5a6ff078f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
